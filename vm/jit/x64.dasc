#include "../../dynasm/dasm_proto.h"
#include "../../dynasm/dasm_x86.h"

#if defined(VM_MINGW)
#include <windows.h>
#elif defined(_WIN32)
#include <Windows.h>
#else
#include <sys/mman.h>
#if !defined(MAP_ANONYMOUS) && defined(MAP_ANON)
#define MAP_ANONYMOUS MAP_ANON
#endif
#endif

#include "../obj.h"
#include "../std/std.h"
#include "x64.h"

static void vm_putchar(int c) {
    printf("%c", c);
}

static void vm_print_nil(void) {
    printf("nil");
}

static void vm_print_ffi(void) {
    printf("<fun>");
}

static void vm_print_str(const char *s) {
    printf("%s", s);
}

static void vm_print_table(vm_table_t *t) {
    printf("<tab: %p>", t);
}

static void vm_print_i64(ptrdiff_t n) {
    printf("%zi", n);
}

static void vm_print_f64(double n) {
    if (fmod(n, 1) == 0) {
        printf("%.0f", n);
    } else {
        printf("%g", n);
    }
}

void *vm_x64_mmap(vm_x64_state_t *state, size_t size, size_t align) {
    vm_x64_mmap_t *map = NULL;
    for (size_t i = 0; i < state->mapbuf.len; i++) {
        vm_x64_mmap_t *cur = &state->mapbuf.mmaps[state->mapbuf.len - i - 1];
        if (cur->used + size <= cur->alloc) {
            map = cur;
            break;
        }
    }
    void *buf = NULL;
    if (map == NULL) {
        size_t blocks = 1;
        if (state->mapbuf.len < 12) {
            blocks = 1 << state->mapbuf.len;
        } else {
            blocks = 1 << 12;
        }
        size_t minsize = 4096 * blocks;
        size_t next_index = state->mapbuf.len + 1;
        if (next_index >= state->mapbuf.alloc) {
            state->mapbuf.alloc += next_index * 2;
            state->mapbuf.mmaps = vm_realloc(state->mapbuf.mmaps, sizeof(vm_x64_mmap_t) * state->mapbuf.alloc);
        }
        if (size < minsize) {
            map = &state->mapbuf.mmaps[next_index - 1];
            map->alloc = minsize;
            state->mapbuf.len = next_index;
            #ifdef __APPLE__
                map->mem = mmap(0, map->alloc, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS | MAP_32BIT | MAP_JIT, -1, 0);
            #else
                map->mem = mmap(0, map->alloc, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS | MAP_32BIT, -1, 0);
            #endif
            map->used = size;
            buf = map->mem;
        } else {
            #ifdef __APPLE__
                buf = mmap(0, map->alloc, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS | MAP_32BIT | MAP_JIT, -1, 0);
            #else
                buf = mmap(0, map->alloc, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS | MAP_32BIT, -1, 0);
            #endif
        }
    } else {
        if (map->used % align != 0) {
            map->used -= map->used % align;            
            map->used += align;
        }
        buf = (void *) (((size_t) (map->mem)) + map->used);
        map->used += size;
    }
    return buf;
}

double *vm_x64_mmap_f64(vm_x64_state_t *state, double v) {
    double *ptr = vm_x64_mmap(state, sizeof(double), 8);
    *ptr = v;
    return ptr;
}

void* vm_x64_encode(vm_x64_state_t *state, dasm_State** d)
{
    size_t size;
    dasm_link(d, &size);
#ifdef _WIN32
    void *buf = VirtualAlloc(0, size, MEM_RESERVE | MEM_COMMIT, PAGE_EXECUTE_READWRITE);
#else
    void *buf = vm_x64_mmap(state, size, 8);
#endif
    dasm_encode(d, buf);
    // static int n = 0;
    // n++;
    // char cbuf[32];
    // sprintf(cbuf, "out%i.bin", n);
    // FILE *out = fopen(cbuf, "wb");
    // fwrite(buf, 1, size, out);
    // fclose(out);
    for (vm_x64_link_t *link = state->links; link != NULL; link = link->next) {
        *link->out = (void *) ((size_t) buf + dasm_getpclabel(d, link->label));
    }
    return buf;
}

vm_x64_cache_t *vm_x64_cache_new(void) {
    vm_x64_cache_t *cache = vm_malloc(sizeof(vm_x64_cache_t));
    *cache = (vm_x64_cache_t){0};
    return cache;
}

vm_block_t *vm_x64_rblock_version(vm_rblock_t *rblock) {
    void *cache = vm_cache_get(&rblock->block->cache, rblock);
    if (cache != NULL) {
        return cache;
    }
    vm_block_t *ret = vm_malloc(sizeof(vm_block_t));
    vm_cache_set(&rblock->block->cache, rblock, ret);
    vm_tags_t *regs = vm_rblock_regs_dup(rblock->regs, 256);
    *ret = *rblock->block;
    ret->label = -1;
    ret->instrs = vm_malloc(sizeof(vm_instr_t) * rblock->block->len);
    ret->args = vm_malloc(sizeof(vm_arg_t) * ret->nargs);
    ret->mark = false;
    for (size_t i = 0; i < ret->nargs; i++) {
        ret->args[i] = rblock->block->args[i];
        if (ret->args[i].type != VM_ARG_REG) {
            __builtin_trap();
        }
    }
    for (size_t ninstr = 0; ninstr < rblock->block->len; ninstr++) {
        vm_instr_t instr = vm_rblock_type_specialize_instr(regs, rblock->block->instrs[ninstr]);
        if (!vm_rblock_type_check_instr(regs, instr)) return NULL;
        for (size_t i = 0; instr.args[i].type != VM_ARG_NONE; i++) {
            if (instr.args[i].type == VM_ARG_REG) {
                instr.args[i].reg_tag = regs->tags[instr.args[i].reg];
            }
        }
        if (instr.op == VM_IOP_SET) {
            if (instr.args[1].type == VM_ARG_REG) {
                instr.args[3] = (vm_arg_t) {
                    .type = VM_ARG_TAG,
                    .tag = instr.args[1].reg_tag,
                };
            } else if (instr.args[1].type == VM_ARG_NUM) {
                instr.args[3] = (vm_arg_t) {
                    .type = VM_ARG_TAG,
                    .tag = VM_TAG_F64,
                };
            }
            if (instr.args[2].type == VM_ARG_REG) {
                instr.args[4] = (vm_arg_t) {
                    .type = VM_ARG_TAG,
                    .tag = instr.args[2].reg_tag,
                };
            } else if (instr.args[2].type == VM_ARG_NUM) {
                instr.args[4] = (vm_arg_t) {
                    .type = VM_ARG_TAG,
                    .tag = VM_TAG_F64,
                };
            }
        }
        ret->instrs[ninstr] = instr;
        if (instr.out.type == VM_ARG_REG) {
            regs->tags[instr.out.reg] = instr.tag;
        }
    }
    vm_branch_t branch = vm_rblock_type_specialize_branch(regs, rblock->block->branch);
    if (!vm_rblock_type_check_branch(regs, branch)) return NULL;
    for (size_t i = 0; branch.args[i].type != VM_ARG_NONE; i++) {
        if (branch.args[i].type == VM_ARG_REG) {
            branch.args[i].reg_tag = regs->tags[branch.args[i].reg];
        }
    }
    switch (branch.op) {
        case VM_BOP_GET: {
            if (branch.args[1].type == VM_ARG_REG) {
                branch.tag = regs->tags[branch.args[1].reg];
            } else if (branch.args[1].type == VM_ARG_NUM) {
                branch.tag = VM_TAG_F64;
            }
            if (branch.args[1].type == VM_ARG_REG) {
                branch.args[3] = (vm_arg_t) {
                    .type = VM_ARG_TAG,
                    .tag = branch.args[1].reg_tag,
                };
            } else if (branch.args[1].type == VM_ARG_NUM) {
                branch.args[3] = (vm_arg_t) {
                    .type = VM_ARG_TAG,
                    .tag = VM_TAG_F64,
                };
            }
            vm_block_t *from = branch.targets[0];
            for (size_t i = 0; i < from->nargs; i++) {
                vm_arg_t *arg = &from->args[i];
                if (arg->type == VM_ARG_REG) {
                    if (arg->reg != branch.out.reg) {
                        arg->reg_tag = regs->tags[arg->reg];
                    }
                }
            }
            for (size_t i = 1; i < VM_TAG_MAX; i++) {
                regs->tags[branch.out.reg] = i;
                branch.rtargets[i] = vm_rblock_new(from, vm_rblock_regs_dup(regs, 256));
            }
            break;
        }
        case VM_BOP_CALL: {
            vm_tags_t *regs2 = vm_rblock_regs_empty(256);
            for (size_t i = 1; branch.args[i].type != VM_ARG_NONE; i++) {
                if (branch.args[i].type == VM_ARG_REG) {
                    regs2->tags[i] = branch.args[i].reg_tag;
                }
            }
            if (branch.args[0].type == VM_ARG_FUNC) {
                branch.args[0] = (vm_arg_t) {
                    .type = VM_ARG_RFUNC,
                    .rfunc = vm_rblock_new(branch.args[0].func, regs2),
                };
            }
            vm_block_t *from = branch.targets[0];
            for (size_t i = 0; i < from->nargs; i++) {
                vm_arg_t *arg = &from->args[i];
                if (arg->type == VM_ARG_REG) {
                    if (arg->reg != branch.out.reg) {
                        arg->reg_tag = regs->tags[arg->reg];
                    }
                }
            }
            for (size_t i = 1; i < VM_TAG_MAX; i++) {
                regs->tags[branch.out.reg] = i;
                branch.rtargets[i] = vm_rblock_new(from, vm_rblock_regs_dup(regs, 256));
            }
            break;
        }
        case VM_BOP_JUMP: {
            branch.targets[0] = vm_x64_rblock_version(vm_rblock_new(branch.targets[0], vm_rblock_regs_dup(regs, 256)));
            if (branch.targets[0] == NULL) {
                return NULL;
            }
            break;
        }
        case VM_BOP_BB:
        case VM_BOP_BEQ:
        case VM_BOP_BLT: {
            branch.targets[0] = vm_x64_rblock_version(vm_rblock_new(branch.targets[0], vm_rblock_regs_dup(regs, 256)));
            branch.targets[1] = vm_x64_rblock_version(vm_rblock_new(branch.targets[1], vm_rblock_regs_dup(regs, 256)));
            if (branch.targets[0] == NULL) {
                return NULL;
            }
            if (branch.targets[1] == NULL) {
                return NULL;
            }
            break;
        }
        case VM_BOP_EXIT:
        case VM_BOP_RET: {
            break;
        }
        default: {
            __builtin_trap();
        }
    }
    ret->branch = branch;
    for (size_t i = 0; i < ret->nargs; i++) {
        if (ret->args[i].type == VM_ARG_REG) {
            ret->args[i].reg_tag = regs->tags[ret->args[i].reg];
        }
    }
    return ret;
}

static const bool vm_x64_is_clobbered[16] = {
    true,  // rax
    true,  // rcx
    true,  // rdx
    false, // rbx
    false, // rsp
    false, // rbp
    true,  // rsi
    true,  // rdi
    true,  // r8
    true,  // r9
    true,  // r10
    true,  // r11
    false, // r12
    false, // r13
    false, // r14
    false, // r15
};

int8_t vm_x64_find_r64(vm_x64_regs_t *regs) {
    for (size_t i = 0; i < 16; i++) {
        size_t r = 15-i;
        if (r != 4) {
            if (regs->r64[r] < 0) {
                return r;
            }
        }
    }
    __builtin_trap();
}

int8_t vm_x64_alloc_r64(vm_x64_regs_t *regs, size_t vmreg) {
    if (regs->vm[vmreg] >= 0) {
        return regs->vm[vmreg];
    }
    int8_t cpureg = vm_x64_find_r64(regs);
    regs->r64[cpureg] = vmreg;
    regs->vm[vmreg] = cpureg;
    return cpureg;
}

int8_t vm_x64_find_f64(vm_x64_regs_t *regs) {
    for (size_t i = 0; i < 8; i++) {
        size_t r = 7-i;
        if (regs->xmm[r] < 0) {
            return r;
        }
    }
    __builtin_trap();
}

int8_t vm_x64_alloc_f64(vm_x64_regs_t *regs, size_t vmreg) {
    if (regs->vm[vmreg] >= 0) {
        return regs->vm[vmreg];
    }
    int8_t cpureg = vm_x64_find_f64(regs);
    regs->xmm[cpureg] = vmreg;
    regs->vm[vmreg] = cpureg;
    return cpureg;
}

void vm_x64_calc_save(vm_x64_reg_save_t *save, vm_x64_regs_t *regs) {
    uint16_t r64s = 0;
    for (size_t i = 0; i < 16; i++) {
        if (regs->r64[i] >= 0) {
            r64s |= (1 << i);
        }
    }
    save->r64 = r64s;
    uint16_t xmms = 0;
    for (size_t i = 0; i < 8; i++) {
        if (regs->xmm[i] >= 0) {
            xmms |= (1 << i);
        }
    }
    save->xmm = xmms;
}

void vm_x64_alloc_block(vm_x64_state_t *state, vm_block_t *block) {
    if (block->mark) {
        return;
    }
    block->mark = true;
    vm_x64_regs_t regs_value;
    vm_x64_regs_t *regs = &regs_value;
    memset(regs, 0xFF, sizeof(vm_x64_regs_t));
    switch (block->branch.op) {
    case VM_BOP_CALL: {
        size_t reg = block->branch.out.reg;
        regs->xmm[0] = reg;
        regs->r64[0] = reg;
        regs->vm[reg] = 0;
        block->branch.pass[0] = vm_malloc(sizeof(int8_t) * block->branch.targets[0]->nargs);
        for (size_t i = 0; i < block->branch.targets[0]->nargs; i++) {
            vm_arg_t arg = block->branch.targets[0]->args[i];
            int8_t val = -1;
            if (arg.type == VM_ARG_REG) {
                if (arg.reg_tag == VM_TAG_F64) {
                    val = vm_x64_alloc_f64(regs, arg.reg);
                } else {
                    val = vm_x64_alloc_r64(regs, arg.reg);
                }
            } else if (arg.type == VM_ARG_CPU_GP) {
                val = vm_x64_alloc_r64(regs, arg.vmreg);
            } else if (arg.type == VM_ARG_CPU_FP) {
                val = vm_x64_alloc_f64(regs, arg.vmreg);
            } else {
                __builtin_trap();
            }
            block->branch.pass[0][i] = val;
        }
        block->branch.out = (vm_arg_t) {
            .type = VM_ARG_CPU0,
            .vmreg = reg,
        };
        regs->xmm[0] = -1;
        regs->r64[0] = -1;
        regs->vm[reg] = -1;
        vm_x64_calc_save(&block->branch.out.save, regs);
        static int8_t argregs[] = {7, 6, 2, 1, 8, 9};
        size_t gp = 0;
        size_t fp = 0;
        for (size_t i = 1; block->branch.args[i].type != VM_ARG_NONE; i++) {
            if (block->branch.args[i].type != VM_ARG_REG) {
                __builtin_trap();
            }
            vm_tag_t tag = block->branch.args[i].reg_tag;
            if (block->branch.args[i].reg_tag == VM_TAG_F64) {
                size_t cpureg = fp++;
                size_t vmreg = block->branch.args[i].reg;
                if (regs->vm[vmreg] >= 0) {
                    block->branch.args[i] = (vm_arg_t) {
                        .type = VM_ARG_CPU_FP,
                        .vmreg = vmreg,
                        .f64 = regs->vm[vmreg],
                    };
                } else if (regs->xmm[cpureg] < 0) {
                    regs->xmm[cpureg] = vmreg;
                    regs->vm[vmreg] = cpureg;
                    block->branch.args[i] = (vm_arg_t) {
                        .type = VM_ARG_CPU_FP,
                        .vmreg = vmreg,
                        .f64 = cpureg,
                    };
                } else {
                    block->branch.args[i] = (vm_arg_t) {
                        .type = VM_ARG_CPU_FP,
                        .vmreg = vmreg,
                        .f64 = vm_x64_alloc_f64(regs, vmreg),
                    };
                }
            } else {
                size_t cpureg = argregs[gp++];
                size_t vmreg = block->branch.args[i].reg;
                if (regs->vm[vmreg] >= 0) {
                    block->branch.args[i] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = vmreg,
                        .r64 = regs->vm[vmreg],
                    };
                } else if (regs->r64[cpureg] < 0) {
                    regs->r64[cpureg] = vmreg;
                    regs->vm[vmreg] = cpureg;
                    block->branch.args[i] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = vmreg,
                        .r64 = cpureg,
                    };
                } else {
                    block->branch.args[i] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = vmreg,
                        .r64 = vm_x64_alloc_r64(regs, vmreg),
                    };
                }
            }
            block->branch.args[i].vmreg_tag = tag;
        }
        break;
    }
    case VM_BOP_GET: {
        size_t reg = block->branch.out.reg;
        regs->xmm[0] = reg;
        regs->r64[0] = reg;
        regs->vm[reg] = 0;
        block->branch.pass[0] = vm_malloc(sizeof(int8_t) * block->branch.targets[0]->nargs);
        for (size_t i = 0; i < block->branch.targets[0]->nargs; i++) {
            vm_arg_t arg = block->branch.targets[0]->args[i];
            int8_t val = -1;
            if (arg.type == VM_ARG_REG) {
                if (arg.reg_tag == VM_TAG_F64) {
                    val = vm_x64_alloc_f64(regs, arg.reg);
                } else {
                    val = vm_x64_alloc_r64(regs, arg.reg);
                }
            } else if (arg.type == VM_ARG_CPU_GP) {
                val = vm_x64_alloc_r64(regs, arg.vmreg);
            } else if (arg.type == VM_ARG_CPU_FP) {
                val = vm_x64_alloc_f64(regs, arg.vmreg);
            } else {
                __builtin_trap();
            }
            block->branch.pass[0][i] = val;
        }
        block->branch.out = (vm_arg_t) {
            .type = VM_ARG_CPU0,
            .vmreg = reg,
        };
        regs->xmm[0] = -1;
        regs->r64[0] = -1;
        regs->vm[reg] = -1;
        vm_x64_calc_save(&block->branch.out.save, regs);
        if (block->branch.args[0].type == VM_ARG_REG) {
            if (block->branch.args[0].reg_tag != VM_TAG_TAB) {
                __builtin_trap();
            }
            block->branch.args[0] = (vm_arg_t) {
                .type = VM_ARG_CPU_GP,
                .vmreg = block->branch.args[0].reg,
                .r64 = vm_x64_alloc_r64(regs, block->branch.args[0].reg),
            };
        }
        if (block->branch.args[1].type == VM_ARG_REG) {
            if (block->branch.args[1].reg_tag == VM_TAG_F64) {
                block->branch.args[1] = (vm_arg_t) {
                    .type = VM_ARG_CPU_FP,
                    .vmreg = block->branch.args[1].reg,
                    .f64 = vm_x64_alloc_f64(regs, block->branch.args[1].reg),
                };
            } else {
                block->branch.args[1] = (vm_arg_t) {
                    .type = VM_ARG_CPU_GP,
                    .vmreg = block->branch.args[1].reg,
                    .r64 = vm_x64_alloc_r64(regs, block->branch.args[1].reg),
                };
            }
        }
        break;
    }
    case VM_BOP_JUMP: {
        vm_x64_alloc_block(state, block->branch.targets[0]);
        block->branch.pass[0] = vm_malloc(sizeof(int8_t) * block->branch.targets[0]->nargs);
        for (size_t i = 0; i < block->branch.targets[0]->nargs; i++) {
            vm_arg_t arg = block->branch.targets[0]->args[i];
            int8_t val = -1;
            if (arg.type == VM_ARG_REG) {
                if (arg.reg_tag == VM_TAG_F64) {
                    val = vm_x64_alloc_f64(regs, arg.reg);
                } else {
                    val = vm_x64_alloc_r64(regs, arg.reg);
                }
            } else if (arg.type == VM_ARG_CPU_GP) {
                val = vm_x64_alloc_r64(regs, arg.vmreg);
            } else if (arg.type == VM_ARG_CPU_FP) {
                val = vm_x64_alloc_f64(regs, arg.vmreg);
            } else {
                __builtin_trap();
            }
            block->branch.pass[0][i] = val;
        }
        break;
    }
    case VM_BOP_BEQ:
    case VM_BOP_BLT: {
        for (size_t bn = 0; bn < 2; bn++) {
            vm_x64_alloc_block(state, block->branch.targets[bn]);
            block->branch.pass[bn] = vm_malloc(sizeof(int8_t) * block->branch.targets[bn]->nargs);
            for (size_t i = 0; i < block->branch.targets[bn]->nargs; i++) {
                vm_arg_t arg = block->branch.targets[bn]->args[i];
                int8_t val = -1;
                if (arg.type == VM_ARG_REG) {
                    if (arg.reg_tag == VM_TAG_F64) {
                        val = vm_x64_alloc_f64(regs, arg.reg);
                    } else {
                        val = vm_x64_alloc_r64(regs, arg.reg);
                    }
                } else if (arg.type == VM_ARG_CPU_GP) {
                    val = vm_x64_alloc_r64(regs, arg.vmreg);
                } else if (arg.type == VM_ARG_CPU_FP) {
                    val = vm_x64_alloc_f64(regs, arg.vmreg);
                } else {
                    __builtin_trap();
                }
                block->branch.pass[bn][i] = val;
            }
        }
        if (block->branch.args[0].type == VM_ARG_REG) {
            if (block->branch.args[0].reg_tag == VM_TAG_F64) {
                block->branch.args[0] = (vm_arg_t) {
                    .type = VM_ARG_CPU_FP,
                    .vmreg = block->branch.args[0].reg,
                    .f64 = vm_x64_alloc_f64(regs, block->branch.args[0].reg),
                };
            } else {
                block->branch.args[0] = (vm_arg_t) {
                    .type = VM_ARG_CPU_GP,
                    .vmreg = block->branch.args[0].reg,
                    .r64 = vm_x64_alloc_r64(regs, block->branch.args[0].reg),
                };
            }
        }
        if (block->branch.args[1].type == VM_ARG_REG) {
            if (block->branch.args[1].reg_tag == VM_TAG_F64) {
                block->branch.args[1] = (vm_arg_t) {
                    .type = VM_ARG_CPU_FP,
                    .vmreg = block->branch.args[1].reg,
                    .f64 = vm_x64_alloc_f64(regs, block->branch.args[1].reg),
                };
            } else {
                block->branch.args[1] = (vm_arg_t) {
                    .type = VM_ARG_CPU_GP,
                    .vmreg = block->branch.args[1].reg,
                    .r64 = vm_x64_alloc_r64(regs, block->branch.args[1].reg),
                };
            }
        }
        break;
    }
    case VM_BOP_EXIT:
    case VM_BOP_RET: {
        if (block->branch.args[0].type == VM_ARG_REG) {
            if (block->branch.args[0].reg_tag == VM_TAG_F64) {
                size_t cpureg = 0;
                size_t vmreg = block->branch.args[0].reg;
                if (regs->vm[vmreg] >= 0) {
                    block->branch.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_FP,
                        .vmreg = vmreg,
                        .f64 = regs->vm[vmreg],
                    };
                } else if (regs->xmm[cpureg] < 0) {
                    regs->xmm[cpureg] = vmreg;
                    regs->vm[vmreg] = cpureg;
                    block->branch.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_FP,
                        .vmreg = vmreg,
                        .f64 = cpureg,
                    };
                } else {
                    block->branch.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_FP,
                        .vmreg = vmreg,
                        .f64 = vm_x64_alloc_f64(regs, vmreg),
                    };
                }
            } else {
                size_t cpureg = 0;
                size_t vmreg = block->branch.args[0].reg;
                if (regs->vm[vmreg] >= 0) {
                    block->branch.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = vmreg,
                        .r64 = regs->vm[vmreg],
                    };
                } else if (regs->r64[cpureg] < 0) {
                    regs->r64[cpureg] = vmreg;
                    regs->vm[vmreg] = cpureg;
                    block->branch.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = vmreg,
                        .r64 = cpureg,
                    };
                } else {
                    block->branch.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = vmreg,
                        .r64 = vm_x64_alloc_r64(regs, vmreg),
                    };
                }
            }
        }
        break;
    }
    default: {
        vm_print_branch(stdout, block->branch);
        printf("\n");
        __builtin_trap();
    }
    }
    ptrdiff_t head = block->len;
    while (head != 0) {
        head -= 1;
        vm_instr_t instr = block->instrs[head];
        if (instr.out.type == VM_ARG_REG) {
            size_t reg = instr.out.reg;
            if (instr.tag == VM_TAG_F64) {
                if (regs->vm[reg] >= 0) {
                    instr.out = (vm_arg_t) {
                        .type = VM_ARG_CPU_FP,
                        .vmreg = reg,
                        .f64 = regs->vm[reg],
                    };
                    regs->vm[reg] = -1;
                    regs->xmm[instr.out.f64] = -1;
                } else {
                    instr.out = (vm_arg_t) {
                        .type = VM_ARG_NONE,
                    };
                }
            } else {
                if (regs->vm[reg] >= 0) {
                    instr.out = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = reg,
                        .r64 = regs->vm[reg],
                    };
                    regs->vm[reg] = -1;
                    regs->r64[instr.out.r64] = -1;
                } else {
                    instr.out = (vm_arg_t) {
                        .type = VM_ARG_NONE,
                    };
                }
            }
        }
        vm_x64_calc_save(&instr.out.save, regs);
        if (instr.op == VM_IOP_SET) {
            static int8_t argregs[] = {7, 6, 2, 1, 8, 9};
            size_t gp = 0;
            size_t fp = 0;
            for (size_t i = 0; i < 3; i++) {
                if (instr.args[i].type == VM_ARG_REG) {
                    if (instr.args[i].reg_tag == VM_TAG_F64) {
                        size_t cpureg = fp++;
                        size_t vmreg = instr.args[i].reg;
                        if (regs->vm[vmreg] >= 0) {
                            instr.args[i] = (vm_arg_t) {
                                .type = VM_ARG_CPU_FP,
                                .vmreg = vmreg,
                                .f64 = regs->vm[vmreg],
                            };
                        } else if (regs->xmm[cpureg] < 0) {
                            regs->xmm[cpureg] = vmreg;
                            regs->vm[vmreg] = cpureg;
                            instr.args[i] = (vm_arg_t) {
                                .type = VM_ARG_CPU_FP,
                                .vmreg = vmreg,
                                .f64 = cpureg,
                            };
                        } else {
                            instr.args[i] = (vm_arg_t) {
                                .type = VM_ARG_CPU_FP,
                                .vmreg = vmreg,
                                .f64 = vm_x64_alloc_f64(regs, vmreg),
                            };
                        }
                    } else {
                        size_t cpureg = argregs[gp++];
                        size_t vmreg = instr.args[i].reg;
                        if (regs->vm[vmreg] >= 0) {
                            instr.args[i] = (vm_arg_t) {
                                .type = VM_ARG_CPU_GP,
                                .vmreg = vmreg,
                                .r64 = regs->vm[vmreg],
                            };
                        } else if (regs->r64[cpureg] < 0) {
                            regs->r64[cpureg] = vmreg;
                            regs->vm[vmreg] = cpureg;
                            instr.args[i] = (vm_arg_t) {
                                .type = VM_ARG_CPU_GP,
                                .vmreg = vmreg,
                                .r64 = cpureg,
                            };
                        } else {
                            instr.args[i] = (vm_arg_t) {
                                .type = VM_ARG_CPU_GP,
                                .vmreg = vmreg,
                                .r64 = vm_x64_alloc_r64(regs, vmreg),
                            };
                        }
                    }
                } else if (instr.args[i].type == VM_ARG_NUM) {
                    fp++;
                } else {
                    __builtin_trap();
                }
            }
        } else if (instr.tag == VM_TAG_F64) {
            switch (instr.op) {
            case VM_IOP_NEW:
            case VM_IOP_STD:
            case VM_IOP_TYPE:
            case VM_IOP_NOP: {
                break;
            }
            case VM_IOP_LEN: {
                if (instr.args[0].type == VM_ARG_REG) {
                    instr.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = instr.args[0].reg,
                        .r64 = vm_x64_alloc_r64(regs, instr.args[0].reg),
                    };
                }
                break;
            }
            case VM_IOP_MOVE: {
                if (instr.args[0].type == VM_ARG_REG) {
                    instr.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_FP,
                        .vmreg = instr.args[0].reg,
                        .f64 = vm_x64_alloc_f64(regs, instr.args[0].reg),
                    };
                }
                break;
            }
            case VM_IOP_ADD:
            case VM_IOP_SUB:
            case VM_IOP_MUL:
            case VM_IOP_DIV: {
                if (instr.args[0].type == VM_ARG_REG) {
                    instr.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_FP,
                        .vmreg = instr.args[0].reg,
                        .f64 = vm_x64_alloc_f64(regs, instr.args[0].reg),
                    };
                }
                if (instr.args[1].type == VM_ARG_REG) {
                    instr.args[1] = (vm_arg_t) {
                        .type = VM_ARG_CPU_FP,
                        .vmreg = instr.args[1].reg,
                        .f64 = vm_x64_alloc_f64(regs, instr.args[1].reg),
                    };
                }
                break;
            }
            case VM_IOP_MOD: {
                if (instr.args[0].type == VM_ARG_REG) {
                    if (regs->xmm[0] < 0) {
                        regs->xmm[0] = instr.args[0].reg;
                        regs->vm[instr.args[0].reg] = 0;
                        instr.args[0] = (vm_arg_t) {
                            .type = VM_ARG_CPU_FP,
                            .vmreg = instr.args[0].reg,
                            .f64 = 0,
                        };
                    } else {
                        instr.args[0] = (vm_arg_t) {
                            .type = VM_ARG_CPU_FP,
                            .vmreg = instr.args[0].reg,
                            .f64 = vm_x64_alloc_f64(regs, instr.args[0].reg),
                        };
                    }
                }
                if (instr.args[1].type == VM_ARG_REG) {
                    if (regs->xmm[0] < 0) {
                        regs->xmm[0] = instr.args[1].reg;
                        regs->vm[instr.args[1].reg] = 0;
                        instr.args[1] = (vm_arg_t) {
                            .type = VM_ARG_CPU_FP,
                            .vmreg = instr.args[1].reg,
                            .f64 = 0,
                        };
                    } else {
                        instr.args[1] = (vm_arg_t) {
                            .type = VM_ARG_CPU_FP,
                            .vmreg = instr.args[1].reg,
                            .f64 = vm_x64_alloc_f64(regs, instr.args[1].reg),
                        };
                    }
                }
                break;
            }
            case VM_IOP_PRINT:
            case VM_IOP_OUT: {
                if (instr.args[0].type == VM_ARG_REG) {
                    if (regs->xmm[0] < 0) {
                        regs->xmm[0] = instr.args[0].reg;
                        regs->vm[instr.args[0].reg] = 0;
                        instr.args[0] = (vm_arg_t) {
                            .type = VM_ARG_CPU_FP,
                            .vmreg = instr.args[0].reg,
                            .f64 = 0,
                        };
                    } else {
                        instr.args[0] = (vm_arg_t) {
                            .type = VM_ARG_CPU_FP,
                            .vmreg = instr.args[0].reg,
                            .f64 = vm_x64_alloc_f64(regs, instr.args[0].reg),
                        };
                    }
                }
                break;
            }
            default: {
                vm_print_instr(stdout, instr);
                printf("\n");
                __builtin_trap();
            }
            }
        } else {
            switch (instr.op) {
            case VM_IOP_NEW:
            case VM_IOP_STD:
            case VM_IOP_TYPE:
            case VM_IOP_NOP: {
                break;
            }
            case VM_IOP_LEN: {
                __builtin_trap();
            }
            case VM_IOP_MOVE: {
                if (instr.args[0].type == VM_ARG_REG) {
                    instr.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = instr.args[0].reg,
                        .r64 = vm_x64_alloc_r64(regs, instr.args[0].reg),
                    };
                }
                break;
            }
            case VM_IOP_ADD:
            case VM_IOP_SUB: {
                if (instr.args[0].type == VM_ARG_REG) {
                    instr.args[0] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = instr.args[0].reg,
                        .r64 = vm_x64_alloc_r64(regs, instr.args[0].reg),
                    };
                }
                if (instr.args[1].type == VM_ARG_REG) {
                    instr.args[1] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = instr.args[1].reg,
                        .r64 = vm_x64_alloc_r64(regs, instr.args[1].reg),
                    };
                }
                break;
            }
            case VM_IOP_MUL:
            case VM_IOP_DIV:
            case VM_IOP_MOD: {
                if (instr.args[0].type == VM_ARG_REG) {
                    if (regs->r64[0] < 0) {
                        regs->r64[0] = instr.args[0].reg;
                        regs->vm[instr.args[0].reg] = 0;
                        instr.args[0] = (vm_arg_t) {
                            .type = VM_ARG_CPU_GP,
                            .vmreg = instr.args[0].reg,
                            .r64 = 0,
                        };
                    } else {
                        instr.args[0] = (vm_arg_t) {
                            .type = VM_ARG_CPU_GP,
                            .vmreg = instr.args[0].reg,
                            .r64 = vm_x64_alloc_r64(regs, instr.args[0].reg),
                        };
                    }
                }
                if (instr.args[1].type == VM_ARG_REG) {
                    instr.args[1] = (vm_arg_t) {
                        .type = VM_ARG_CPU_GP,
                        .vmreg = instr.args[1].reg,
                        .r64 = vm_x64_alloc_r64(regs, instr.args[1].reg),
                    };
                }
                break;
            }
            case VM_IOP_PRINT:
            case VM_IOP_OUT: {
                if (instr.args[0].type == VM_ARG_REG) {
                    size_t cpureg = 7;
                    size_t vmreg = instr.args[0].reg;
                    if (regs->vm[vmreg] >= 0) {
                        instr.args[0] = (vm_arg_t) {
                            .type = VM_ARG_CPU_GP,
                            .vmreg = vmreg,
                            .r64 = regs->vm[vmreg],
                        };
                    } else if (regs->r64[cpureg] < 0) {
                        regs->r64[cpureg] = vmreg;
                        regs->vm[vmreg] = cpureg;
                        instr.args[0] = (vm_arg_t) {
                            .type = VM_ARG_CPU_GP,
                            .vmreg = vmreg,
                            .r64 = cpureg,
                        };
                    } else {
                        instr.args[0] = (vm_arg_t) {
                            .type = VM_ARG_CPU_GP,
                            .vmreg = vmreg,
                            .r64 = vm_x64_alloc_r64(regs, vmreg),
                        };
                    }
                }
                break;
            }
            default: {
                vm_print_instr(stdout, instr);
                printf("\n");
                __builtin_trap();
            }
            }
        }
        block->instrs[head] = instr;
    }
    for (size_t i = 0; i < block->nargs; i++) {
        if (block->args[i].type == VM_ARG_REG) {
            if (block->args[i].reg_tag == VM_TAG_F64) {
                size_t reg = block->args[i].reg;
                block->args[i] = (vm_arg_t) {
                    .type = VM_ARG_CPU_FP,
                    .vmreg = reg,
                    .f64 = vm_x64_alloc_f64(regs, reg),
                };
            } else {
                size_t reg = block->args[i].reg;
                block->args[i] = (vm_arg_t) {
                    .type = VM_ARG_CPU_GP,
                    .vmreg = reg,
                    .r64 = vm_x64_alloc_r64(regs, reg),
                };
            }
        }
    }
}

|.arch x64
|.section code

void vm_x64_comp_save(dasm_State **Dst, vm_x64_reg_save_t save) {
    size_t count = 0;
    for (size_t i = 0; i < 16; i++) {
        if (save.r64 & (1 << i)) {
            | mov [rsp + (8 * count + 8)], Rq(i)
            count += 1;
        }
    }
    for (size_t i = 0; i < 8; i++) {
        if (save.xmm & (1 << i)) {
            | movsd qword [rsp + (8 * count + 8)], xmm(i)
            count += 1;
        }
    }
}

void vm_x64_comp_unsave(dasm_State **Dst, vm_x64_reg_save_t save) {
    size_t count = 0;
    for (size_t i = 0; i < 16; i++) {
        if (save.r64 & (1 << i)) {
            | mov Rq(i), [rsp + (8 * count + 8)]
            count += 1;
        }
    }
    for (size_t i = 0; i < 8; i++) {
        if (save.xmm & (1 << i)) {
            | movsd xmm(i), qword [rsp + (8 * count + 8)]
            count += 1;
        }
    }
}

int8_t vm_x64_find_r64_not(vm_x64_reg_save_t save, uint16_t not) {
    for (size_t i = 0; i < 16; i++) {
        if (!(save.r64 & (1 << i)) && !(not & (1 << i))) {
            return i;
        }
    }
    __builtin_trap();
}

int8_t vm_x64_find_f64_not(vm_x64_reg_save_t save, uint16_t not) {
    for (size_t i = 0; i < 16; i++) {
        if (!(save.xmm & (1 << i)) && !(not & (1 << i))) {
            return i;
        }
    }
    __builtin_trap();
}

void vm_x64_block_comp(vm_x64_state_t *state, vm_block_t *block, dasm_State **Dst, int8_t *pass) {
    if (state->count + 4 + VM_TAG_MAX*2 >= state->pc_alloc) {
        state->pc_alloc = (state->count + 4 + VM_TAG_MAX*2) * 2;
        dasm_growpc(Dst, state->pc_alloc);
    }
    {
        size_t count = 0;
        int8_t from[16];
        int8_t to[16];
        for (size_t i = 0; i < block->nargs; i++) {
            vm_arg_t arg = block->args[i];
            if (arg.type == VM_ARG_CPU_GP) {
                to[count] = arg.r64;
                from[count] = pass[i];
                if (from[count] != to[count]) {
                    count += 1;
                }
            } else if (arg.type == VM_ARG_CPU_FP) {
            } else {
                __builtin_trap();
            }
        }
        for (size_t i = 0; i < count; i++) {
            bool stack = false;
            for (size_t j = i + 1; j < count; j++) {
                if (from[j] == to[i]) {
                    stack = true;
                    break;
                }
            }
            if (stack) {
                | mov [rsp+(i*8+8)], Rq(from[i])
            } else {
                | mov Rq(to[i]), Rq(from[i])
            }
        }
        for (size_t i = 0; i < count; i++) {
            bool stack = false;
            for (size_t j = i + 1; j < count; j++) {
                if (from[j] == to[i]) {
                    stack = true;
                    break;
                }
            }
            if (stack) {
                | mov Rq(to[i]), [rsp+(i*8+8)]
            }
        }
    }
    {
        size_t count = 0;
        int8_t from[8];
        int8_t to[8];
        for (size_t i = 0; i < block->nargs; i++) {
            vm_arg_t arg = block->args[i];
            if (arg.type == VM_ARG_CPU_GP) {
            } else if (arg.type == VM_ARG_CPU_FP) {
                to[count] = arg.f64;
                from[count] = pass[i];
                if (from[count] != to[count]) {
                    count += 1;
                }
            } else {
                __builtin_trap(); 
            }
        }
        for (size_t i = 0; i < count; i++) {
            bool stack = false;
            for (size_t j = i + 1; j < count; j++) {
                if (from[j] == to[i]) {
                    stack = true;
                    break;
                }
            }
            if (stack) {
                | movsd qword [rsp+(i*8+8)], xmm(from[i])
            } else {
                | movsd xmm(to[i]), xmm(from[i])
            }
        }
        for (size_t i = 0; i < count; i++) {
            bool stack = false;
            for (size_t j = i + 1; j < count; j++) {
                if (from[j] == to[i]) {
                    stack = true;
                    break;
                }
            }
            if (stack) {
                | movsd xmm(to[i]), qword [rsp+(i*8+8)]
            }
        }
    }
    if (block->epoch == state->epoch) {
        | jmp =>block->label
        return;
    }
    block->epoch = state->epoch;
    block->label = state->count++;
    |=>block->label:
    for (size_t instr_num = 0; instr_num < block->len; instr_num++) {
        vm_instr_t instr = block->instrs[instr_num];
        switch (instr.op) {
        case VM_IOP_NOP: {
            break;
        }
        case VM_IOP_STD: {
            | mov64 Rq(instr.out.r64), ((size_t) (void*) state->std)
            break;
        }
        case VM_IOP_MOVE: {
            if (instr.out.type == VM_ARG_CPU_GP) {
                if (instr.args[0].type == VM_ARG_CPU_GP) {
                    if (instr.args[0].r64 != instr.out.r64) {
                        | mov Rq(instr.out.r64), Rq(instr.args[0].r64)
                    }
                } else if (instr.args[0].type == VM_ARG_STR) {
                    | mov64 Rq(instr.out.r64), ((size_t) (instr.args[0].str))
                } else if (instr.args[0].type == VM_ARG_FUNC) {
                    | mov64 Rq(instr.out.r64), ((size_t) (instr.args[0].func))
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    | mov Rq(instr.out.r64), ((int32_t) (instr.args[0].num))
                } else if (instr.args[0].type == VM_ARG_NIL) {
                } else if (instr.args[0].type == VM_ARG_UNK) {
                } else {
                    vm_print_instr(stdout, instr);
                    printf("\n");
                    __builtin_trap();
                }
            } else if (instr.out.type == VM_ARG_CPU_FP) {
                if (instr.args[0].type == VM_ARG_CPU_FP) {
                    if (instr.args[0].f64 != instr.out.f64) {
                        | movsd xmm(instr.out.f64), xmm(instr.args[0].f64)
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    double *ptr = vm_x64_mmap_f64(state, instr.args[0].num);
                    | movsd xmm(instr.out.f64), qword [((int32_t) (size_t) (ptr))]
                } else {
                    __builtin_trap();
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_ADD: {
            if (instr.out.type == VM_ARG_CPU_GP) {
                if (instr.args[0].type == VM_ARG_CPU_GP) {
                    if (instr.args[1].type == VM_ARG_CPU_GP) {
                        if (instr.out.r64 == instr.args[0].r64) {
                            | add Rq(instr.out.r64), Rq(instr.args[1].r64)
                        } else {
                            | lea Rq(instr.out.r64), [Rq(instr.args[0].r64)+Rq(instr.args[1].r64)]
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        if (instr.out.r64 == instr.args[0].r64) {
                            | add Rq(instr.out.r64), ((int32_t) (instr.args[1].num))
                        } else {
                            | lea Rq(instr.out.r64), [Rq(instr.args[0].r64)+((int32_t) (instr.args[1].num))]
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_CPU_GP) {
                        if (instr.out.r64 == instr.args[1].r64) {
                            | add Rq(instr.out.r64), ((int32_t) (instr.args[0].num))
                        } else {
                            | lea Rq(instr.out.r64), [Rq(instr.args[1].r64)+((int32_t) (instr.args[0].num))]
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        | mov Rd(instr.out.r64), (((int32_t) (instr.args[0].num))+((int32_t) (instr.args[1].num)))
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
            } else if (instr.out.type == VM_ARG_CPU_FP) {
                if (instr.args[0].type == VM_ARG_CPU_FP) {
                    if (instr.args[1].type == VM_ARG_CPU_FP) {
                        if (instr.out.f64 == instr.args[0].f64) {
                            | addsd xmm(instr.out.f64), xmm(instr.args[1].f64) 
                        } else {
                            | vaddsd xmm(instr.out.f64), xmm(instr.args[0].f64), xmm(instr.args[1].f64) 
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        double *ptr = vm_x64_mmap_f64(state, instr.args[1].num);
                        if (instr.out.f64 == instr.args[0].f64) {
                            | addsd xmm(instr.out.f64), qword [((int32_t) (size_t) ptr)]
                        } else {
                            | vaddsd xmm(instr.out.f64), xmm(instr.args[0].f64), qword [((int32_t) (size_t) ptr)]
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_CPU_FP) {
                        int8_t arg0reg = vm_x64_find_f64_not(instr.out.save, 1 << instr.args[1].f64);
                        double *num = vm_x64_mmap_f64(state, instr.args[0].num);
                        | movsd xmm(arg0reg), qword [((int32_t) (size_t) num)]
                        | vaddsd xmm(instr.out.f64), xmm(arg0reg), xmm(instr.args[1].f64)
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        double *num = vm_x64_mmap_f64(state, instr.args[0].num + instr.args[1].num);
                        | movsd xmm(instr.out.f64), qword [((int32_t) (size_t) num)]
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_SUB: {
            if (instr.out.type == VM_ARG_CPU_GP) {
                if (instr.args[0].type == VM_ARG_CPU_GP) {
                    if (instr.args[1].type == VM_ARG_CPU_GP) {
                        if (instr.out.r64 == instr.args[0].r64) {
                            | sub Rq(instr.out.r64), Rq(instr.args[1].r64)
                        } else {
                            | mov Rq(instr.out.r64), Rq(instr.args[0].r64)
                            | sub Rq(instr.out.r64), Rq(instr.args[1].r64)
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        if (instr.out.r64 == instr.args[0].r64) {
                            | sub Rq(instr.out.r64), ((int32_t) (instr.args[1].num))
                        } else {
                            | lea Rq(instr.out.r64), [Rq(instr.args[0].r64)-((int32_t) (instr.args[1].num))]
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_CPU_GP) {
                        if (instr.out.r64 == instr.args[1].r64) {
                            | sub Rq(instr.out.r64), ((int32_t) (instr.args[0].num))
                            | neg Rq(instr.out.r64)
                        } else {
                            | mov Rd(instr.out.r64), ((int32_t) (instr.args[0].num))
                            | sub Rq(instr.out.r64), Rq(instr.args[1].r64)
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        | mov Rd(instr.out.r64), (((int32_t) (instr.args[0].num))-((int32_t) (instr.args[1].num)))
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
            } else if (instr.out.type == VM_ARG_CPU_FP) {
                if (instr.args[0].type == VM_ARG_CPU_FP) {
                    if (instr.args[1].type == VM_ARG_CPU_FP) {
                        if (instr.out.f64 == instr.args[0].f64) {
                            | subsd xmm(instr.out.f64), xmm(instr.args[1].f64) 
                        } else {
                            | vsubsd xmm(instr.out.f64), xmm(instr.args[0].f64), xmm(instr.args[1].f64) 
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        double *ptr = vm_x64_mmap_f64(state, instr.args[1].num);
                        if (instr.out.f64 == instr.args[0].f64) {
                            | subsd xmm(instr.out.f64), qword [((int32_t) (size_t) ptr)]
                        } else {
                            | vsubsd xmm(instr.out.f64), xmm(instr.args[0].f64), qword [((int32_t) (size_t) ptr)]
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_CPU_FP) {
                        int8_t arg0reg = vm_x64_find_f64_not(instr.out.save, 1 << instr.args[1].f64);
                        double *num = vm_x64_mmap_f64(state, instr.args[0].num);
                        | movsd xmm(arg0reg), qword [((int32_t) (size_t) num)]
                        | vsubsd xmm(instr.out.f64), xmm(arg0reg), xmm(instr.args[1].f64)
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        double *num = vm_x64_mmap_f64(state, instr.args[0].num - instr.args[1].num);
                        | movsd xmm(instr.out.f64), qword [((int32_t) (size_t) num)]
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_MUL: {
            if (instr.out.type == VM_ARG_CPU_GP) {
                size_t out = 0;
                if (instr.out.save.r64 & (1 << 0)) {
                    | mov [rsp+8], rax
                }
                if (instr.out.save.r64 & (1 << 2)) {
                    | mov [rsp+16], rdx
                }
                if (instr.args[0].type == VM_ARG_CPU_GP) {
                    if (instr.args[0].r64 != 0) {
                        | mov rax, Rq(instr.args[0].r64)
                    }
                    if (instr.args[1].type == VM_ARG_CPU_GP) {
                        | imul Rq(instr.args[1].r64)
                        if (instr.out.r64 != out) {
                            | mov Rq(instr.out.r64), Rq(out)
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        size_t r = 16;
                        for (size_t reg = 0; reg < 16; reg++) {
                            if (reg == 0 || reg == 2 || reg == 4) {
                                continue;
                            }
                            if (!(instr.out.save.r64 & (1 << reg))) {
                                r = reg;
                                break;
                            }
                        }
                        if (r == 16) {
                            __builtin_trap();
                        }
                        | mov Rd(r), ((int32_t) (instr.args[1].num))
                        | imul Rq(r)
                        if (instr.out.r64 != out) {
                            | mov Rq(instr.out.r64), Rq(out)
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_CPU_GP) {
                        __builtin_trap();
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        __builtin_trap();
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
                if (instr.out.save.r64 & (1 << 0)) {
                    | mov rax, [rsp+8]
                }
                if (instr.out.save.r64 & (1 << 2)) {
                    | mov rdx, [rsp+16]
                }
            } else if (instr.out.type == VM_ARG_CPU_FP) {
                if (instr.args[0].type == VM_ARG_CPU_FP) {
                    if (instr.args[1].type == VM_ARG_CPU_FP) {
                        if (instr.out.f64 == instr.args[0].f64) {
                            | mulsd xmm(instr.out.f64), xmm(instr.args[1].f64) 
                        } else {
                            | vmulsd xmm(instr.out.f64), xmm(instr.args[0].f64), xmm(instr.args[1].f64) 
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        double *num = vm_x64_mmap_f64(state, instr.args[1].num);
                        if (instr.out.f64 == instr.args[0].f64) {
                            | mulsd xmm(instr.out.f64), qword [((int32_t) (size_t) num)]
                        } else {
                            | vmulsd xmm(instr.out.f64), xmm(instr.args[0].f64), qword [((int32_t) (size_t) num)]
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_CPU_FP) {
                        int8_t arg0reg = vm_x64_find_f64_not(instr.out.save, 1 << instr.args[1].f64);
                        double *num = vm_x64_mmap_f64(state, instr.args[0].num);
                        | movsd xmm(arg0reg), qword [((int32_t) (size_t) num)]
                        | vmulsd xmm(instr.out.f64), xmm(arg0reg), xmm(instr.args[1].f64)
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        double *num = vm_x64_mmap_f64(state, instr.args[0].num * instr.args[1].num);
                        | movsd xmm(instr.out.f64), qword [((int32_t) (size_t) num)]
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_DIV:
        case VM_IOP_MOD: {
            if (instr.out.type == VM_ARG_CPU_GP) {
                size_t out = instr.op == VM_IOP_MOD ? 2 : 0;
                if (instr.out.save.r64 & (1 << 0)) {
                    | mov [rsp+8], rax
                }
                if (instr.out.save.r64 & (1 << 2)) {
                    | mov [rsp+16], rdx
                }
                if (instr.args[0].type == VM_ARG_CPU_GP) {
                    if (instr.args[0].r64 != 0) {
                        | mov rax, Rq(instr.args[0].r64)
                    }
                    | xor edx, edx
                    if (instr.args[1].type == VM_ARG_CPU_GP) {
                        | idiv Rq(instr.args[1].r64)
                        if (instr.out.r64 != out) {
                            | mov Rq(instr.out.r64), Rq(out)
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        size_t r = 16;
                        for (size_t reg = 0; reg < 16; reg++) {
                            if (reg == 0 || reg == 2 || reg == 4) {
                                continue;
                            }
                            if (!(instr.out.save.r64 & (1 << reg))) {
                                r = reg;
                                break;
                            }
                        }
                        if (r == 16) {
                            __builtin_trap();
                        }
                        | mov Rd(r), ((int32_t) (instr.args[1].num))
                        | idiv Rq(r)
                        if (instr.out.r64 != out) {
                            | mov Rq(instr.out.r64), Rq(out)
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_CPU_GP) {
                        vm_x64_comp_save(Dst, instr.out.save);
                        | mov rax, ((int32_t) (instr.args[0].num))
                        | cqo
                        | idiv Rq(instr.args[1].r64)
                        if (instr.out.r64 != out) {
                            | mov Rq(instr.out.r64), Rq(out)
                        }
                        vm_x64_comp_unsave(Dst, instr.out.save);
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        if (instr.op == VM_IOP_MOD) {
                            | mov Rq(instr.out.r64), (int) fmod(instr.args[0].num, instr.args[1].num)
                        } else {
                            | mov Rq(instr.out.r64), (instr.args[0].num / instr.args[1].num)
                        }
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
                if (instr.out.save.r64 & (1 << 0)) {
                    | mov rax, [rsp+8]
                }
                if (instr.out.save.r64 & (1 << 2)) {
                    | mov rdx, [rsp+16]
                }
            } else if (instr.out.type == VM_ARG_CPU_FP) {
                if (instr.op == VM_IOP_DIV) {
                    if (instr.args[0].type == VM_ARG_CPU_FP) {
                        if (instr.args[1].type == VM_ARG_CPU_FP) {
                            if (instr.out.f64 == instr.args[0].f64) {
                                | divsd xmm(instr.out.f64), xmm(instr.args[1].f64) 
                            } else {
                                | vdivsd xmm(instr.out.f64), xmm(instr.args[0].f64), xmm(instr.args[1].f64) 
                            }
                        } else if (instr.args[1].type == VM_ARG_NUM) {
                            double *ptr = vm_x64_mmap_f64(state, instr.args[1].num);
                            if (instr.out.f64 == instr.args[0].f64) {
                                | divsd xmm(instr.out.f64), qword [((int32_t) (size_t) ptr)]
                            } else {
                                | vdivsd xmm(instr.out.f64), xmm(instr.args[0].f64), qword [((int32_t) (size_t) ptr)]
                            }
                        } else {
                            __builtin_trap();
                        }
                    } else if (instr.args[0].type == VM_ARG_NUM) {
                        if (instr.args[1].type == VM_ARG_CPU_FP) {
                            double *arg0ptr = vm_x64_mmap_f64(state, instr.args[0].num);
                            uint8_t arg0reg = vm_x64_find_f64_not(instr.out.save, 1 << instr.args[1].f64);
                            | movsd xmm(arg0reg), qword [((int32_t) (size_t) arg0ptr)]
                            | vdivsd xmm(instr.out.f64), xmm(arg0reg), xmm(instr.args[1].f64)
                        } else if (instr.args[1].type == VM_ARG_NUM) {
                            double *arg0ptr = vm_x64_mmap_f64(state, instr.args[0].num / instr.args[1].num);
                            | movsd xmm(instr.out.f64), qword [((int32_t) (size_t) arg0ptr)]
                        } else {
                            __builtin_trap();
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.op == VM_IOP_MOD) {
                    if (instr.args[0].type == VM_ARG_CPU_FP) {
                        if (instr.args[1].type == VM_ARG_CPU_FP) {
                            int8_t tmp0 = vm_x64_find_f64_not(instr.out.save, (1 << instr.args[0].f64) | (1 << instr.args[1].f64));
                            | vdivsd xmm(tmp0), xmm(instr.args[0].f64), xmm(instr.args[1].f64)
                            | roundsd xmm(tmp0), xmm(tmp0), 9
                            | mulsd xmm(tmp0), xmm(instr.args[1].f64)
                            | vsubsd xmm(instr.out.f64), xmm(instr.args[0].f64), xmm(tmp0)
                        } else if (instr.args[1].type == VM_ARG_NUM) {
                            int8_t tmp0 = vm_x64_find_f64_not(instr.out.save, (1 << instr.args[0].f64));
                            double *ptr = vm_x64_mmap_f64(state, instr.args[1].num);
                            | vdivsd xmm(tmp0), xmm(instr.args[0].f64), qword [((int32_t) (size_t) ptr)]
                            | roundsd xmm(tmp0), xmm(tmp0), 9
                            | mulsd xmm(tmp0), qword [((int32_t) (size_t) ptr)]
                            | vsubsd xmm(instr.out.f64), xmm(instr.args[0].f64), xmm(tmp0)
                        } else {
                            __builtin_trap();
                        }
                    } else if (instr.args[0].type == VM_ARG_NUM) {
                        if (instr.args[1].type == VM_ARG_CPU_FP) {
                            int8_t arg1 = instr.args[1].f64;
                            int8_t arg0 = vm_x64_find_f64_not(instr.out.save, (1 << arg1));
                            double *arg0ptr = vm_x64_mmap_f64(state, instr.args[0].num);
                            int8_t tmp = vm_x64_find_f64_not(instr.out.save, (1 << arg0) | (1 << arg1));
                            | movsd xmm(arg0), qword [((int32_t) (size_t) arg0ptr)]
                            | vdivsd xmm(tmp), xmm(arg0), xmm(arg1)
                            | roundsd xmm(tmp), xmm(tmp), 9
                            | mulsd xmm(tmp), xmm(arg1)
                            | vsubsd xmm(instr.out.f64), xmm(arg0), xmm(tmp)
                        } else if (instr.args[1].type == VM_ARG_NUM) {
                            double *arg0ptr = vm_x64_mmap_f64(state, fmod(instr.args[0].num, instr.args[1].num));
                            | movsd xmm(instr.out.f64), qword [((int32_t) (size_t) arg0ptr)]
                        } else {
                            __builtin_trap();
                        }
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_OUT: {
            vm_x64_comp_save(Dst, instr.out.save);
            if (instr.args[0].type == VM_ARG_CPU_GP) {
                if (instr.args[0].r64 != 7) {
                    | mov rdi, Rq(instr.args[0].r64)
                }
            } else if (instr.args[0].type == VM_ARG_CPU_FP) {
                if (instr.args[0].f64 != 0) {
                    | movsd xmm0, xmm(instr.args[0].f64)
                }
            } else if (instr.args[0].type == VM_ARG_NUM) {
                | mov edi, ((int32_t) (instr.args[0].num))
            } else {
                __builtin_trap();
            }
            | mov64 rax, ((uint64_t) &vm_putchar)
            | call rax
            vm_x64_comp_unsave(Dst, instr.out.save);
            break;
        }
        case VM_IOP_PRINT: {
            vm_x64_comp_save(Dst, instr.out.save);
            if (instr.args[0].type == VM_ARG_CPU_GP) {
                if (instr.args[0].r64 != 7) {
                    | mov rdi, Rq(instr.args[0].r64)
                }
            } else if (instr.args[0].type == VM_ARG_CPU_FP) {
                if (instr.args[0].f64 != 0) {
                    | movsd xmm0, xmm(instr.args[0].f64)
                }
            } else if (instr.args[0].type == VM_ARG_NUM) {
                double *ptr = vm_x64_mmap_f64(state, instr.args[0].num);
                | movsd xmm0, qword [((int32_t) (size_t) (ptr))]
            } else {
                __builtin_trap();
            }
            if (instr.tag == VM_TAG_I64) {
                | mov64 rax, ((uint64_t) &vm_print_i64)
            } else if (instr.tag == VM_TAG_F64) {
                | mov64 rax, ((uint64_t) &vm_print_f64)
            } else if (instr.tag == VM_TAG_STR) {
                | mov64 rax, ((uint64_t) &vm_print_str)
            } else if (instr.tag == VM_TAG_TAB) {
                | mov64 rax, ((uint64_t) &vm_print_table)
            } else if (instr.tag == VM_TAG_NIL) {
                | mov64 rax, ((uint64_t) &vm_print_nil)
            } else if (instr.tag == VM_TAG_FFI) {
                | mov64 rax, ((uint64_t) &vm_print_ffi)
            } else {
                __builtin_trap();
            }
            | call rax
            vm_x64_comp_unsave(Dst, instr.out.save);
            break;
        }
        case VM_IOP_NEW: {
            vm_x64_comp_save(Dst, instr.out.save);
            | mov64 rax, ((uint64_t) &vm_table_new)
            | call rax
            if (instr.out.type == VM_ARG_CPU_GP) {
                if (instr.out.r64 != 0) {
                    | mov Rq(instr.out.r64), rax
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            vm_x64_comp_unsave(Dst, instr.out.save);
            break;
        }
        case VM_IOP_LEN: {
            vm_x64_comp_save(Dst, instr.out.save);
            if (instr.args[0].type == VM_ARG_CPU_GP) {
                if (instr.args[0].r64 != 7) {
                    | mov rdi, Rq(instr.args[0].r64)
                }
            } else {
                __builtin_trap();
            }
            | mov64 rax, ((uint64_t) (&vm_table_len))
            | call rax
            if (instr.out.type != VM_ARG_CPU_FP) {
                __builtin_trap();
            }
            if (instr.out.f64 != 0) {
                | movsd xmm(instr.out.f64), xmm0
            }
            vm_x64_comp_unsave(Dst, instr.out.save);
            break;
        }
        case VM_IOP_SET: {
            vm_x64_comp_save(Dst, instr.out.save);
            int8_t reg = vm_x64_find_r64_not(instr.out.save, (1<<7) | (1<<6));
            | sub rsp, 24
            if (instr.args[1].type == VM_ARG_CPU_GP) {
                | mov [rsp], Rq(instr.args[1].r64)
            } else if (instr.args[1].type == VM_ARG_CPU_FP) {
                | movsd qword [rsp], xmm(instr.args[1].f64)
            } else if (instr.args[1].type == VM_ARG_NUM) {
                | mov64 Rq(reg), (* (uint64_t *) (&instr.args[1].num))
                | mov [rsp], Rq(reg)
            } else {
                __builtin_trap();
            }
            if (instr.args[2].type == VM_ARG_CPU_GP) {
                | mov [rsp+0x08], Rq(instr.args[2].r64)
            } else if (instr.args[2].type == VM_ARG_CPU_FP) {
                | movsd qword [rsp+0x08], xmm(instr.args[2].f64)
            } else if (instr.args[2].type == VM_ARG_NUM) {
                | mov64 Rq(reg), (* (uint64_t *) (&instr.args[2].num))
                | mov [rsp+0x08], Rq(reg)
            } else {
                __builtin_trap();
            }
            if (instr.args[0].type == VM_ARG_CPU_GP) {
                | mov rdi, Rq(instr.args[0].r64)
            } else {
                __builtin_trap();
            }
            | mov64 Rq(reg), ((uint64_t) (&vm_table_set_pair)) 
            | mov dword [rsp+0x10], (instr.args[3].tag)
            | mov dword [rsp+0x14], (instr.args[4].tag)
            | mov rsi, rsp
            | sub rsp, 8
            | call Rq(reg)
            | add rsp, 32
            vm_x64_comp_unsave(Dst, instr.out.save);
            break;
        }
        default: {
            __builtin_trap(); // bad instr
        }
        }
    }
    switch (block->branch.op) {
    case VM_BOP_JUMP: {
        vm_x64_block_comp(state, block->branch.targets[0], Dst, block->branch.pass[0]);
        break;
    }
    case VM_BOP_CALL: {
        if (block->branch.args[0].type == VM_ARG_REG) {
            if (block->branch.args[0].reg_tag == VM_TAG_FFI) {
                void **ptrs = vm_x64_mmap(state, sizeof(void *) * VM_TAG_MAX, 8);
                for (size_t i = 1; i < VM_TAG_MAX; i++) {
                    vm_x64_link_t *link = vm_malloc(sizeof(vm_x64_link_t));
                    link->label = state->count++;
                    link->out = &ptrs[i];
                    *link->out = NULL;
                    link->next = state->links;
                    block->branch.rtargets[i]->block->pass = block->branch.pass[0];
                    link->block = block->branch.rtargets[i];
                    link->block->block->isfunc = false;
                    link->save = block->branch.out.save;
                    if (i == VM_TAG_F64) {
                        link->save.xmm |= 1;
                    } else {
                        link->save.r64 |= 1;
                    }
                    state->links = link;
                }
                vm_x64_comp_save(Dst, block->branch.out.save);
                size_t nargs = 0;
                for (size_t i = 1; block->branch.args[i].type != VM_ARG_NONE; i++) {
                    nargs += 1;
                }
                | sub rsp, 16
                | mov qword [rsp], 0
                | mov dword [rsp+8], VM_TAG_UNK
                for (size_t i = nargs; i >= 1; i--) {
                    | sub rsp, 16
                    if (block->branch.args[i].type == VM_ARG_CPU_GP) {
                        | mov [rsp], Rq(block->branch.args[i].r64)
                    } else if (block->branch.args[i].type == VM_ARG_CPU_FP) {
                        | movsd qword [rsp], xmm(block->branch.args[i].f64)
                    } else {
                        __builtin_trap();
                    }
                    | mov dword [rsp+8], (block->branch.args[i].vmreg_tag)
                }
                int8_t reg = vm_x64_find_r64_not(block->branch.out.save, (1 << 0) | (1 << 2));
                if (block->branch.args[0].r64 == 7) {
                    | mov rax, Rq(block->branch.args[0].r64)
                    | mov Rq(7), rsp
                    | call rax
                } else {
                    | mov Rq(7), rsp
                    | call Rq(block->branch.args[0].r64)
                }
                | add rsp, 16*(nargs+1)
                | cmp edx, VM_TAG_F64
                | je >1
                | mov Rd(reg), edx
                vm_x64_comp_unsave(Dst, block->branch.out.save);
                | jmp qword [Rd(reg)*8+((int32_t) (size_t) (ptrs))]
                |1:
                | vmovd xmm0, rax
                vm_x64_comp_unsave(Dst, block->branch.out.save);
                | jmp qword [((int32_t) (size_t) (ptrs+VM_TAG_F64))]
                break;
            } else if (block->branch.args[0].reg_tag == VM_TAG_FUN) {
                void **next_ptrs = vm_x64_mmap(state, sizeof(void *) * VM_TAG_MAX, 8);
                size_t labels[VM_TAG_MAX];
                for (size_t i = 1; i < VM_TAG_MAX; i++) {
                    vm_x64_link_t *link = vm_malloc(sizeof(vm_x64_link_t));
                    labels[i] = link->label = state->count++;
                    link->out = &next_ptrs[i];
                    link->next = state->links;
                    block->branch.rtargets[i]->block->pass = block->branch.pass[0];
                    link->block = block->branch.rtargets[i];
                    link->block->block->isfunc = false;
                    link->save = block->branch.out.save;
                    if (i == VM_TAG_F64) {
                        link->save.xmm |= 1;
                    } else {
                        link->save.r64 |= 1;
                    }
                    state->links = link;
                }
                vm_x64_comp_save(Dst, block->branch.out.save);
                static int8_t argregs[] = {7, 6, 2, 1, 8, 9};
                uint16_t save_gp = 0;
                uint16_t save_fp = 0;
                size_t gp = 0;
                size_t fp = 0;
                for (size_t i = 1; block->branch.args[i].type != VM_ARG_NONE; i++) {
                    if (block->branch.args[i].type == VM_ARG_CPU_GP) {
                        size_t n = argregs[gp++];
                        save_gp |= (1 << n);
                        if (block->branch.args[i].r64 != n) {
                            | mov Rq(n), Rq(block->branch.args[i].r64)
                        }
                    } else if (block->branch.args[i].type == VM_ARG_CPU_FP) {
                        size_t n = fp++;
                        save_fp |= (1 << n);
                        if (block->branch.args[i].f64 != n) {
                            | movsd xmm(n), xmm(block->branch.args[i].f64)
                        }
                    } else {
                        __builtin_trap();
                    }
                }
                void **jbufs = vm_x64_mmap(state, sizeof(void *) * VM_TAG_MAX, 8);
                vm_x64_link_t *link = vm_malloc(sizeof(vm_x64_link_t));
                link->label = state->count++;
                link->out = (void **) vm_x64_mmap(state, sizeof(void *), 8);
                *link->out = NULL;
                link->next = state->links;
                link->block = block->branch.args[0].rfunc;
                link->block->block->isfunc = true;
                link->save = block->branch.out.save;
                link->save.r64 |= save_gp;
                link->save.xmm |= save_fp;
                state->links = link;
                | push ((int32_t) (size_t) (jbufs))
                | jmp qword [((int32_t) (size_t) (link->out))]
                for (size_t i = 1; i < VM_TAG_MAX; i++) {
                    vm_x64_link_t *link = vm_malloc(sizeof(vm_x64_link_t));
                    link->out = &jbufs[i];
                    link->next = state->links;
                    link->block = NULL;
                    link->save = block->branch.out.save;
                    if (block->branch.out.save.r64 != 0 || block->branch.out.save.xmm != 0) {
                        link->label = state->count++;
                        |=>link->label:
                        vm_x64_comp_unsave(Dst, block->branch.out.save);
                        | jmp qword [((int32_t) (size_t) (next_ptrs+i))]
                    } else {
                        link->label = labels[i];
                    }
                    state->links = link;
                }
            } else {
                vm_print_branch(stdout, block->branch);
                printf("\n");
                fflush(stdout);
                __builtin_trap();
            }
        } else {
            void **next_ptrs = vm_x64_mmap(state, sizeof(void *) * VM_TAG_MAX, 8);
            size_t labels[VM_TAG_MAX];
            for (size_t i = 1; i < VM_TAG_MAX; i++) {
                vm_x64_link_t *link = vm_malloc(sizeof(vm_x64_link_t));
                labels[i] = link->label = state->count++;
                link->out = &next_ptrs[i];
                link->next = state->links;
                block->branch.rtargets[i]->block->pass = block->branch.pass[0];
                link->block = block->branch.rtargets[i];
                link->block->block->isfunc = false;
                link->save = block->branch.out.save;
                if (i == VM_TAG_F64) {
                    link->save.xmm |= 1;
                } else {
                    link->save.r64 |= 1;
                }
                state->links = link;
            }
            vm_x64_comp_save(Dst, block->branch.out.save);
            static int8_t argregs[] = {7, 6, 2, 1, 8, 9};
            uint16_t save_gp = 0;
            uint16_t save_fp = 0;
            size_t gp = 0;
            size_t fp = 0;
            for (size_t i = 1; block->branch.args[i].type != VM_ARG_NONE; i++) {
                if (block->branch.args[i].type == VM_ARG_CPU_GP) {
                    size_t n = argregs[gp++];
                    save_gp |= (1 << n);
                    if (block->branch.args[i].r64 != n) {
                        | mov Rq(n), Rq(block->branch.args[i].r64)
                    }
                } else if (block->branch.args[i].type == VM_ARG_CPU_FP) {
                    size_t n = fp++;
                    save_fp |= (1 << n);
                    if (block->branch.args[i].f64 != n) {
                        | movsd xmm(n), xmm(block->branch.args[i].f64)
                    }
                } else {
                    __builtin_trap();
                }
            }
            if (block->branch.args[0].type == VM_ARG_FFI) {
                | mov64 rax, ((size_t) block->branch.args[0].ffi)
                | call rax
                vm_x64_comp_unsave(Dst, block->branch.out.save);
            } else {
                void **jbufs = vm_x64_mmap(state, sizeof(void *) * VM_TAG_MAX, 8);
                vm_x64_link_t *link = vm_malloc(sizeof(vm_x64_link_t));
                link->label = state->count++;
                link->out = (void **) vm_x64_mmap(state, sizeof(void *), 8);
                *link->out = NULL;
                link->next = state->links;
                link->block = block->branch.args[0].rfunc;
                link->block->block->isfunc = true;
                link->save = block->branch.out.save;
                link->save.r64 |= save_gp;
                link->save.xmm |= save_fp;
                state->links = link;
                | push ((int32_t) (size_t) (jbufs))
                | jmp qword [((int32_t) (size_t) (link->out))]
                for (size_t i = 1; i < VM_TAG_MAX; i++) {
                    vm_x64_link_t *link = vm_malloc(sizeof(vm_x64_link_t));
                    link->out = &jbufs[i];
                    link->next = state->links;
                    link->block = NULL;
                    link->save = block->branch.out.save;
                    if (block->branch.out.save.r64 != 0 || block->branch.out.save.xmm != 0) {
                        link->label = state->count++;
                        |=>link->label:
                        vm_x64_comp_unsave(Dst, block->branch.out.save);
                        | jmp qword [((int32_t) (size_t) (next_ptrs+i))]
                    } else {
                        link->label = labels[i];
                    }
                    state->links = link;
                }
            }
        }
        break;
    }
    case VM_BOP_RET: {
        if (block->branch.args[0].type == VM_ARG_CPU_GP) {
            if (block->branch.args[0].r64 != 0) {
                | mov rax, Rq(block->branch.args[0].r64)
            }
        } else if (block->branch.args[0].type == VM_ARG_CPU_FP) {
            if (block->branch.args[0].f64 != 0) {
                | movsd xmm0, xmm(block->branch.args[0].f64)
            }
        } else if (block->branch.args[0].type == VM_ARG_NUM) {
            double *ptr = vm_x64_mmap_f64(state, block->branch.args[0].num);
            | movsd xmm0, qword [((int32_t) (size_t) ptr)]
        } else if (block->branch.args[0].type == VM_ARG_NIL) {
            block->branch.tag = VM_TAG_NIL;
        } else {
            __builtin_trap();
        }
        | add rsp, state->push
        | pop rdx
        | jmp qword [rdx+(block->branch.tag*8)]        
        break;
    }
    case VM_BOP_GET: {
        void **ptrs = vm_x64_mmap(state, sizeof(void *) * VM_TAG_MAX, 8);
        for (size_t i = 1; i < VM_TAG_MAX; i++) {
            vm_x64_link_t *link = vm_malloc(sizeof(vm_x64_link_t));
            link->label = state->count++;
            link->out = &ptrs[i];
            *link->out = NULL;
            link->next = state->links;
            block->branch.rtargets[i]->block->pass = block->branch.pass[0];
            link->block = block->branch.rtargets[i];
            link->block->block->isfunc = false;
            link->save = block->branch.out.save;
            if (i == VM_TAG_F64) {
                link->save.xmm |= 1;
            } else {
                link->save.r64 |= 1;
            }
            state->links = link;
        }
        vm_x64_comp_save(Dst, block->branch.out.save);
        int8_t reg = vm_x64_find_r64_not(block->branch.out.save, 1 << 0);
        | sub rsp, 24
        if (block->branch.args[1].type == VM_ARG_CPU_GP) {
            | mov [rsp], Rq(block->branch.args[1].r64)
        } else if (block->branch.args[1].type == VM_ARG_CPU_FP) {
            | movsd qword [rsp], xmm(block->branch.args[1].f64)
        } else if (block->branch.args[1].type == VM_ARG_NUM) {
            | mov64 Rq(reg), (* (uint64_t *) (&block->branch.args[1].num))
            | mov [rsp], Rq(reg)
        } else {
            __builtin_trap();
        }
        if (block->branch.args[0].type == VM_ARG_CPU_GP) {
            | mov rdi, Rq(block->branch.args[0].r64)
        } else {
            __builtin_trap();
        }
        | mov64 Rq(reg), ((uint64_t) (&vm_table_get_pair)) 
        | mov dword [rsp+0x10], (block->branch.args[3].tag)
        | mov rsi, rsp
        | sub rsp, 8
        | call Rq(reg)
        | add rsp, 8
        | mov Rd(reg), [rsp+0x14]
        | cmp Rd(reg), VM_TAG_F64
        | je >1
        | mov rax, [rsp+0x08]
        | add rsp, 24
        vm_x64_comp_unsave(Dst, block->branch.out.save);
        | jmp qword [Rd(reg)*8+((int32_t) (size_t) (ptrs))]
        |1:
        | movsd xmm0, qword [rsp+0x08]
        | add rsp, 24
        vm_x64_comp_unsave(Dst, block->branch.out.save);
        | jmp qword [((int32_t) (size_t) (ptrs+VM_TAG_F64))]
        break;
    }
    case VM_BOP_BEQ:
    case VM_BOP_BLT: {
        size_t t = state->count++;
        if (block->branch.op == VM_BOP_BLT) {
            if (block->branch.args[0].type == VM_ARG_CPU_GP) {
                if (block->branch.args[1].type == VM_ARG_CPU_GP) {
                    | cmp Rq(block->branch.args[0].r64), Rq(block->branch.args[1].r64)
                    | jb =>t
                } else if (block->branch.args[1].type == VM_ARG_NUM) {
                    | cmp Rq(block->branch.args[0].r64), ((int32_t) (block->branch.args[1].num))
                    | jb =>t
                } else {
                    __builtin_trap();
                }
            } else if (block->branch.args[0].type == VM_ARG_CPU_FP) {
                if (block->branch.args[1].type == VM_ARG_CPU_FP) {
                    | ucomisd xmm(block->branch.args[0].f64), xmm(block->branch.args[1].f64)
                    | jb =>t
                } else if (block->branch.args[1].type == VM_ARG_NUM) {
                    double *val = vm_x64_mmap_f64(state, block->branch.args[1].num);
                    | ucomisd xmm(block->branch.args[0].f64), qword [((int32_t) (size_t) val)]
                    | jb =>t
                } else {
                    __builtin_trap();
                }
            } else if (block->branch.args[0].type == VM_ARG_NUM) {
                if (block->branch.args[1].type == VM_ARG_CPU_GP) {
                    | cmp Rq(block->branch.args[1].r64), ((int32_t) (block->branch.args[0].num))
                    | ja =>t
                } else if (block->branch.args[1].type == VM_ARG_CPU_FP) {
                    double *val = vm_x64_mmap_f64(state, block->branch.args[0].num);
                    | ucomisd xmm(block->branch.args[1].f64), qword [((int32_t) (size_t) val)]
                    | ja =>t
                } else if (block->branch.args[1].type == VM_ARG_NUM) {
                    if (block->branch.args[0].num < block->branch.args[1].num) {
                        | jmp =>t
                    }
                } else {
                    __builtin_trap();
                }
            } else {
                __builtin_trap();
            }
        } else {
            if (block->branch.args[0].type == VM_ARG_CPU_GP) {
                if (block->branch.args[1].type == VM_ARG_CPU_GP) {
                    | cmp Rq(block->branch.args[0].r64), Rq(block->branch.args[1].r64)
                    | je =>t
                } else if (block->branch.args[1].type == VM_ARG_NUM) {
                    | cmp Rq(block->branch.args[0].r64), ((int32_t) (block->branch.args[1].num))
                    | je =>t
                } else {
                    __builtin_trap();
                }
            } else if (block->branch.args[0].type == VM_ARG_CPU_FP) {
                if (block->branch.args[1].type == VM_ARG_CPU_FP) {
                    | ucomisd xmm(block->branch.args[0].f64), xmm(block->branch.args[1].f64)
                    | je =>t
                } else if (block->branch.args[1].type == VM_ARG_NUM) {
                    double *val = vm_x64_mmap_f64(state, block->branch.args[1].num);
                    | ucomisd xmm(block->branch.args[0].f64), qword [((int32_t) (size_t) val)]
                    | je =>t
                } else {
                    __builtin_trap();
                }
            } else if (block->branch.args[0].type == VM_ARG_NUM) {
                if (block->branch.args[1].type == VM_ARG_CPU_GP) {
                    | cmp Rq(block->branch.args[1].r64), ((int32_t) (block->branch.args[0].num))
                    | je =>t
                } else if (block->branch.args[1].type == VM_ARG_CPU_FP) {
                    double *val = vm_x64_mmap_f64(state, block->branch.args[0].num);
                    | ucomisd xmm(block->branch.args[1].f64), qword [((int32_t) (size_t) val)]
                    | je =>t
                } else if (block->branch.args[1].type == VM_ARG_NUM) {
                    if (block->branch.args[0].num == block->branch.args[1].num) {
                        | jmp =>t
                    }
                } else {
                    __builtin_trap();
                }
            } else {
                __builtin_trap();
            }
        }
        vm_x64_block_comp(state, block->branch.targets[1], Dst, block->branch.pass[1]);
        |=>t:
        vm_x64_block_comp(state, block->branch.targets[0], Dst, block->branch.pass[0]);
        break;
    }
    case VM_BOP_EXIT: {
        uint8_t reg = vm_x64_find_r64_not(block->branch.out.save, (1 << 0) | (1 << 2));
        | mov64 Rq(reg), ((uint64_t) (&state->exitptr))
        | mov rsp, [Rq(reg)]
        if (block->branch.args[0].type == VM_ARG_CPU_GP) {
            if (block->branch.args[0].r64 != 0) {
                | mov rax, Rq(block->branch.args[0].r64)
            }
            | mov edx, block->branch.tag
        } else if (block->branch.args[0].type == VM_ARG_CPU_FP) {
            | movd rax, xmm(block->branch.args[0].f64)
            | mov edx, VM_TAG_F64
        } else if (block->branch.args[0].type == VM_ARG_STR) {
            | mov64 rax, ((size_t) (block->branch.args[0].str))
            | mov edx, VM_TAG_STR
        } else if (block->branch.args[0].type == VM_ARG_NUM) {
            void *mem = vm_x64_mmap_f64(state, block->branch.args[0].num);
            | mov rax, [((int32_t) (size_t) mem)]
            | mov edx, VM_TAG_F64
        } else {
            | mov edx, VM_TAG_NIL
        }
        size_t n = 0;
        for (size_t i = 0; i < 16; i++) {
            if (!vm_x64_is_clobbered[i] && i != 4 && i != 0 && i != 2) {
                | mov Rq(i), qword [rsp + (n*8+8)]
                n += 1;
            }
        }
        | add rsp, 8*8+16
        | ret
        break;
    }
    default: {
        __builtin_trap(); // branch
    }
    }
}

void *vm_x64_func_comp(vm_x64_state_t *state, vm_rblock_t *rblock) {
    if (rblock->cache != NULL) {
        return rblock->cache;
    }
    vm_block_t *block = vm_x64_rblock_version(rblock);
    if (block == NULL) {
        vm_print_block(stderr, rblock->block);
        __builtin_trap();
    }
    size_t old_count = state->count;
    size_t old_push = state->push;
    size_t old_pc_alloc = state->pc_alloc;
    vm_x64_link_t *old_links = state->links;
    state->pc_alloc = 16 + VM_TAG_MAX * 2;
    state->links = NULL;
    state->count = 1;
    state->push = 16 * 8 + 8;
    state->epoch += 1;
    dasm_State* d = NULL;
    dasm_State** Dst = &d;
    dasm_init(Dst, DASM_MAXSECTION);
    |.globals lbl_
    void* labels[lbl__MAX];
    dasm_setupglobal(Dst, labels, lbl__MAX);
    |.actionlist act
    dasm_setup(Dst, act);
    |.code
    |->main:
    dasm_growpc(Dst, state->pc_alloc);
    if (state->exitptr == NULL) {
        | sub rsp, 8*8+16
        size_t n = 0;
        for (size_t i = 0; i < 16; i++) {
            if (!vm_x64_is_clobbered[i] && i != 4) {
                | mov qword [rsp + (n*8+8)], Rq(i)
                n += 1;
            }
        }
        for (size_t i = 0; i < 8; i++) {
            | xorps xmm(i), xmm(i)
        }
        | mov64 rax, ((uint64_t) (&state->exitptr))
        | mov [rax], rsp
    }
    vm_x64_alloc_block(state, block);
    if (block->isfunc) {
        | sub rsp, state->push
        static int8_t vm_sysv_argregs[] = {7, 6, 2, 1, 8, 9};
        size_t fp = 0;
        size_t gp = 0;
        int8_t regs[24];
        for (size_t i = 0; i < block->nargs; i++) {
            if (block->args[i].type == VM_ARG_CPU_FP) {
                regs[i] = fp++;
            } else {
                regs[i] = vm_sysv_argregs[gp++];
            }
        }
        vm_x64_block_comp(state, block, Dst, regs);
    } else {
        vm_x64_block_comp(state, block, Dst, block->pass);
    }
    |=>0:
    for (vm_x64_link_t *link = state->links; link != NULL; link = link->next) {
        if (link->block == NULL) {
            continue;
        }
        |=>link->label:
        size_t push = 8*8+16*8;
        if (link->block->block->isfunc) {
            push |= 8;
        }
        | sub rsp, push
        vm_x64_comp_save(Dst, link->save);
        | mov64 rdi, ((uint64_t) (state))
        | mov64 rsi, ((uint64_t) (link->block))
        | mov64 rax, ((uint64_t) (vm_x64_func_comp))
        | call rax
        | mov [((int32_t) (size_t) (link->out))], rax
        vm_x64_comp_unsave(Dst, link->save);
        | add rsp, push
        | jmp qword [((int32_t) (size_t) (link->out))]
    }
    vm_x64_encode(state, Dst);
    void *fn = labels[lbl_main];
    rblock->cache = fn;
    state->pc_alloc = old_pc_alloc;
    state->count = old_count;
    state->push = old_push;
    state->links = old_links;
    return fn;
}

void *vm_x64_full_comp(vm_x64_state_t *state, vm_block_t *block) {
    vm_tags_t *regs = vm_rblock_regs_empty(256);
    block->isfunc = true;
    vm_rblock_t *rblock = vm_rblock_new(block, regs);
    return vm_x64_func_comp(state, rblock);
}

#include "../std/std.h"

vm_std_value_t vm_x64_run(vm_block_t *block, vm_table_t *std, vm_std_value_t *args) {
    vm_x64_state_t state = (vm_x64_state_t){
        .std = std,
    };
    void *code = vm_x64_full_comp(&state, block);
    vm_std_value_t(*fn)(void) = code;
    return fn();
}
