#include "../../dynasm/dasm_proto.h"
#include "../../dynasm/dasm_x86.h"

#if defined(VM_MINGW)
#include <windows.h>
#elif defined(_WIN32)
#include <Windows.h>
#else
#include <sys/mman.h>
#if !defined(MAP_ANONYMOUS) && defined(MAP_ANON)
#define MAP_ANONYMOUS MAP_ANON
#endif
#endif

#include "../obj.h"
#include "x64.h"

static void vm_putchar(int c) {
    printf("%c", c);
}

static void vm_print_nil(vm_table_t *t) {
    printf("nil");
}

static void vm_print_table(vm_table_t *t) {
    printf("table: %p", t);
}

static void vm_print_i64(ptrdiff_t n) {
    printf("%zi", n);
}

void *vm_x64_mmap(vm_x64_state_t *state, size_t size) {
    vm_x64_mmap_t *map = NULL;
    for (size_t i = 0; i < state->mapbuf.len; i++) {
        vm_x64_mmap_t *cur = &state->mapbuf.mmaps[state->mapbuf.len - i - 1];
        if (cur->used + size <= cur->alloc) {
            map = cur;
            break;
        }
    }
    void *buf = NULL;
    if (map == NULL) {
        size_t blocks = 1;
        if (state->mapbuf.len < 12) {
            blocks = 1 << state->mapbuf.len;
        } else {
            blocks = 1 << 12;
        }
        size_t minsize = 4096 * blocks;
        size_t next_index = state->mapbuf.len + 1;
        if (next_index >= state->mapbuf.alloc) {
            state->mapbuf.alloc += next_index * 2;
            state->mapbuf.mmaps = vm_realloc(state->mapbuf.mmaps, sizeof(vm_x64_mmap_t) * state->mapbuf.alloc);
        }
        if (size < minsize) {
            map = &state->mapbuf.mmaps[next_index - 1];
            map->alloc = minsize;
            state->mapbuf.len = next_index;
            map->mem = mmap(0, map->alloc, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS | MAP_32BIT, -1, 0);
            map->used = size;
            buf = map->mem;
        } else {
            buf = mmap(0, map->alloc, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS | MAP_32BIT, -1, 0);
        }
    } else {
        buf = (void *) (((size_t) (map->mem)) + map->used);
        map->used += size;
    }
    return buf;
}

void* vm_x64_encode(vm_x64_state_t *state, dasm_State** d)
{
    size_t size;
    dasm_link(d, &size);
#ifdef _WIN32
    void *buf = VirtualAlloc(0, size, MEM_RESERVE | MEM_COMMIT, PAGE_EXECUTE_READWRITE);
#else
    void *buf = vm_x64_mmap(state, size);
#endif
    dasm_encode(d, buf);
    for (vm_x64_link_t *link = state->links; link != NULL; link = link->next) {
        *link->out = (void *) ((size_t) buf + dasm_getpclabel(d, link->label));
    }
    // static FILE *f = NULL;
    // // FILE *f = NULL;
    // if (f == NULL) {
    //     f = fopen("out.bin", "wb");
    // }
    // fwrite(buf, size, 1, f);
    // // fclose(f);
    return buf;
}

vm_x64_cache_t *vm_x64_cache_new(void) {
    vm_x64_cache_t *cache = vm_malloc(sizeof(vm_x64_cache_t));
    *cache = (vm_x64_cache_t){0};
    return cache;
}

vm_block_t *vm_x64_rblock_version(vm_rblock_t *rblock) {
    if (rblock->cache == NULL) {
        rblock->cache = vm_malloc(sizeof(vm_cache_t));
    }
    void *cache = vm_cache_get(&rblock->block->cache, rblock);
    if (cache != NULL) {
        return cache;
    }
    vm_block_t *ret = vm_malloc(sizeof(vm_block_t));
    vm_tags_t *regs = vm_rblock_regs_dup(rblock->regs, 256);
    vm_cache_set(&rblock->block->cache, rblock, ret);
    *ret = *rblock->block;
    ret->label = -1;
    ret->impl = NULL;
    ret->instrs = vm_malloc(sizeof(vm_instr_t) * rblock->block->len);
    ret->args = vm_malloc(sizeof(vm_arg_t) * ret->nargs);
    ret->mark = false;
    for (size_t i = 0; i < ret->nargs; i++) {
        ret->args[i] = rblock->block->args[i];
    }
    for (size_t ninstr = rblock->start; ninstr < rblock->block->len; ninstr++) {
        vm_instr_t instr = vm_rblock_type_specialize_instr(regs, rblock->block->instrs[ninstr]);
        if (!vm_rblock_type_check_instr(regs, instr)) return NULL;
        if (instr.op == VM_IOP_CALL) {
            vm_tags_t *regs2 = vm_rblock_regs_empty(256);
            for (size_t i = 1; instr.args[i].type != VM_ARG_NONE; i++) {
                if (instr.args[i].type == VM_ARG_REG) {
                    regs2->tags[i] = regs->tags[instr.args[i].reg];
                }
            }
            vm_rblock_t *rblock2 = vm_rblock_new(instr.args[0].func, regs2);
            vm_block_t *cur = vm_x64_rblock_version(rblock2);
            instr.args[0].func = cur;
        }
        if (instr.op == VM_IOP_SET) {
            if (instr.args[1].type == VM_ARG_REG) {
                instr.args[3] = (vm_arg_t) {
                    .type = VM_ARG_TAG,
                    .tag = regs->tags[instr.args[1].reg],
                };
            } else if (instr.args[1].type == VM_ARG_NUM) {
                instr.args[3] = (vm_arg_t) {
                    .type = VM_ARG_TAG,
                    .tag = VM_TAG_I64,
                };
            }
            if (instr.args[2].type == VM_ARG_REG) {
                instr.args[4] = (vm_arg_t) {
                    .type = VM_ARG_TAG,
                    .tag = regs->tags[instr.args[2].reg],
                };
            } else if (instr.args[2].type == VM_ARG_NUM) {
                instr.args[4] = (vm_arg_t) {
                    .type = VM_ARG_TAG,
                    .tag = VM_TAG_I64,
                };
            }
        }
        ret->instrs[ninstr] = instr;
        if (instr.out.type == VM_ARG_REG) {
            regs->tags[instr.out.reg] = instr.tag;
        }
    }
    vm_branch_t branch = vm_rblock_type_specialize_branch(regs, rblock->block->branch);
    if (!vm_rblock_type_check_branch(regs, branch)) return NULL;
    switch (branch.op) {
        case VM_BOP_GET: {
            if (branch.args[1].type == VM_ARG_REG) {
                branch.tag = regs->tags[branch.args[1].reg];
            } else if (branch.args[1].type == VM_ARG_NUM) {
                branch.tag = VM_TAG_I64;
            }
            vm_block_t *from = branch.targets[0];
            for (size_t i = 1; i < VM_TAG_MAX; i++) {
                regs->tags[branch.out.reg] = i;
                branch.rtargets[i] = vm_rblock_new(from, vm_rblock_regs_dup(regs, 256));
            }
            break;
        }
        case VM_BOP_JUMP: {
            branch.targets[0] = vm_x64_rblock_version(vm_rblock_new(branch.targets[0], vm_rblock_regs_dup(regs, 256)));
            break;
        }
        case VM_BOP_BB: {
            branch.targets[0] = vm_x64_rblock_version(vm_rblock_new(branch.targets[0], vm_rblock_regs_dup(regs, 256)));
            branch.targets[1] = vm_x64_rblock_version(vm_rblock_new(branch.targets[1], vm_rblock_regs_dup(regs, 256)));
            break;
        }
        case VM_BOP_BLT: {
            branch.targets[0] = vm_x64_rblock_version(vm_rblock_new(branch.targets[0], vm_rblock_regs_dup(regs, 256)));
            branch.targets[1] = vm_x64_rblock_version(vm_rblock_new(branch.targets[1], vm_rblock_regs_dup(regs, 256)));
            break;
        }
        case VM_BOP_BEQ: {
            branch.targets[0] = vm_x64_rblock_version(vm_rblock_new(branch.targets[0], vm_rblock_regs_dup(regs, 256)));
            branch.targets[1] = vm_x64_rblock_version(vm_rblock_new(branch.targets[1], vm_rblock_regs_dup(regs, 256)));
            break;
        }
        case VM_BOP_RET: {
            break;
        }
        case VM_BOP_EXIT: {
            break;
        }
        default: {
            __builtin_trap();
        }
    }
    ret->branch = branch;
    return ret;
}

static const bool vm_x64_is_clobbered[16] = {
    true,  // rax
    true,  // rcx
    true,  // rdx
    false, // rbx
    false, // rsp
    false, // rbp
    true,  // rsi
    true,  // rdi
    true,  // r8
    true,  // r9
    true,  // r10
    true,  // r11
    false, // r12
    false, // r13
    false, // r14
    false, // r15
};

int8_t vm_x64_find_reg(int16_t *cpuregs) {
    for (size_t i = 0; i < 16; i++) {
        if (vm_x64_is_clobbered[15-i]) {
            if (cpuregs[15-i] < 0) {
                return 15-i;
            }
        }
    }
    __builtin_trap();
}

int8_t vm_x64_reg_alloc(int8_t *vmregs, int16_t *cpuregs, size_t vmreg) {
    if (vmregs[vmreg] >= 0) {
        return vmregs[vmreg];
    }
    int8_t cpureg = vm_x64_find_reg(cpuregs);
    cpuregs[cpureg] = vmreg;
    vmregs[vmreg] = cpureg;
    return cpureg;
}

void vm_x64_reg_alloc_block(vm_x64_state_t *state, vm_block_t *block) {
    if (block->mark) {
        return;
    }
    block->mark = true;
    int8_t vmregs[256];
    for (size_t i = 0; i < 256; i++) {
        vmregs[i] = -1;
    }
    int16_t cpuregs[16];
    for (size_t i = 0; i < 16; i++) {
        cpuregs[i] = -1;
    }
    switch (block->branch.op) {
    case VM_BOP_EXIT: {
        break;
    }
    case VM_BOP_GET: {
        block->branch.pass[0] = vm_malloc(sizeof(int8_t) * block->branch.targets[0]->nargs);
        for (size_t i = 0; i < block->branch.targets[0]->nargs; i++) {
            vm_arg_t arg = block->branch.targets[0]->args[i];
            int8_t val = -1;
            if (arg.type == VM_ARG_REG) {
                val = vm_x64_reg_alloc(vmregs, cpuregs, arg.reg);
            } else if (arg.type == VM_ARG_X64) {
                val = vm_x64_reg_alloc(vmregs, cpuregs, arg.vmreg);
            } else {
                __builtin_trap();
            }
            block->branch.pass[0][i] = val;
        }
        size_t reg = block->branch.out.reg;
        if (vmregs[reg] >= 0) {
            block->branch.out = (vm_arg_t) {
                .type = VM_ARG_X64,
                .vmreg = reg,
                .x64 = vmregs[reg],
            };
            vmregs[reg] = -1;
            cpuregs[block->branch.out.x64] = -1;
        } else {
            __builtin_trap();
        }
        uint16_t save = 0;
        for (size_t i = 0; i < 16; i++) {
            if (cpuregs[i] >= 0) {
                save |= (1 << i);
            }
        }
        block->branch.out.save = save;
        if (block->branch.args[0].type == VM_ARG_REG) {
            size_t argreg = block->branch.args[0].reg;
            block->branch.args[0] = (vm_arg_t) {
                .type = VM_ARG_X64,
                .vmreg = argreg,
                .x64 = vm_x64_reg_alloc(vmregs, cpuregs, argreg),
            };
        }
        if (block->branch.args[1].type == VM_ARG_REG) {
            size_t argreg = block->branch.args[0].reg;
            block->branch.args[1] = (vm_arg_t) {
                .type = VM_ARG_X64,
                .vmreg = argreg,
                .x64 = vm_x64_reg_alloc(vmregs, cpuregs, argreg),
            };
        }
        break;
    }
    case VM_BOP_JUMP: {
        vm_x64_reg_alloc_block(state, block->branch.targets[0]);
        block->branch.pass[0] = vm_malloc(sizeof(int8_t) * block->branch.targets[0]->nargs);
        for (size_t i = 0; i < block->branch.targets[0]->nargs; i++) {
            vm_arg_t arg = block->branch.targets[0]->args[i];
            int8_t val = -1;
            if (arg.type == VM_ARG_REG) {
                val = vm_x64_reg_alloc(vmregs, cpuregs, arg.reg);
            } else if (arg.type == VM_ARG_X64) {
                val = vm_x64_reg_alloc(vmregs, cpuregs, arg.vmreg);
            } else {
                __builtin_trap();
            }
            block->branch.pass[0][i] = val;
        }
        break;
    }
    case VM_BOP_BEQ:
    case VM_BOP_BLT: {
        for (size_t bn = 0; bn < 2; bn++) {
            vm_x64_reg_alloc_block(state, block->branch.targets[bn]);
            block->branch.pass[bn] = vm_malloc(sizeof(int8_t) * block->branch.targets[bn]->nargs);
            for (size_t i = 0; i < block->branch.targets[bn]->nargs; i++) {
                vm_arg_t arg = block->branch.targets[bn]->args[i];
                int8_t val = -1;
                if (arg.type == VM_ARG_REG) {
                    val = vm_x64_reg_alloc(vmregs, cpuregs, arg.reg);
                } else if (arg.type == VM_ARG_X64) {
                    val = vm_x64_reg_alloc(vmregs, cpuregs, arg.vmreg);
                } else {
                    __builtin_trap();
                }
                block->branch.pass[bn][i] = val;
            }
        }
        if (block->branch.args[0].type == VM_ARG_REG) {
            block->branch.args[0] = (vm_arg_t) {
                .type = VM_ARG_X64,
                .vmreg = block->branch.args[0].reg,
                .x64 = vm_x64_reg_alloc(vmregs, cpuregs, block->branch.args[0].reg),
            };
        }
        if (block->branch.args[1].type == VM_ARG_REG) {
            block->branch.args[1] = (vm_arg_t) {
                .type = VM_ARG_X64,
                .vmreg = block->branch.args[1].reg,
                .x64 = vm_x64_reg_alloc(vmregs, cpuregs, block->branch.args[1].reg),
            };
        }
        break;
    }
    case VM_BOP_RET: {
        if (block->branch.args[0].type == VM_ARG_REG) {
            block->branch.args[0] = (vm_arg_t) {
                .type = VM_ARG_X64,
                .vmreg = block->branch.args[0].reg,
                .x64 = vm_x64_reg_alloc(vmregs, cpuregs, block->branch.args[0].reg),
            };
        }
        break;
    }
    default: {
        vm_print_branch(stdout, block->branch);
        printf("\n");
        __builtin_trap();
    }
    }
    ptrdiff_t head = block->len;
    while (head != 0) {
        head -= 1;
        vm_instr_t instr = block->instrs[head];
        if (instr.out.type == VM_ARG_REG) {
            size_t reg = instr.out.reg;
            if (vmregs[reg] >= 0) {
                instr.out = (vm_arg_t) {
                    .type = VM_ARG_X64,
                    .vmreg = reg,
                    .x64 = vmregs[reg],
                };
                vmregs[reg] = -1;
                cpuregs[instr.out.x64] = -1;
            } else {
                instr.out = (vm_arg_t) {
                    .type = VM_ARG_NONE,
                };
            }
        }
        uint16_t save = 0;
        for (size_t i = 0; i < 16; i++) {
            if (cpuregs[i] >= 0) {
                save |= (1 << i);
            }
        }
        instr.out.save = save;
        switch (instr.op) {
        case VM_IOP_NEW:
        case VM_IOP_NOP: {
            break;
        }
        case VM_IOP_MOVE: {
            if (instr.args[0].type == VM_ARG_REG) {
                instr.args[0] = (vm_arg_t) {
                    .type = VM_ARG_X64,
                    .vmreg = instr.args[0].reg,
                    .x64 = vm_x64_reg_alloc(vmregs, cpuregs, instr.args[0].reg),
                };
            }
            break;
        }
        case VM_IOP_ADD:
        case VM_IOP_SUB: {
            if (instr.args[0].type == VM_ARG_REG) {
                instr.args[0] = (vm_arg_t) {
                    .type = VM_ARG_X64,
                    .vmreg = instr.args[0].reg,
                    .x64 = vm_x64_reg_alloc(vmregs, cpuregs, instr.args[0].reg),
                };
            }
            if (instr.args[1].type == VM_ARG_REG) {
                instr.args[1] = (vm_arg_t) {
                    .type = VM_ARG_X64,
                    .vmreg = instr.args[1].reg,
                    .x64 = vm_x64_reg_alloc(vmregs, cpuregs, instr.args[1].reg),
                };
            }
            break;
        }
        case VM_IOP_SET: {
            static int8_t argregs[] = {7, 6, 2, 1, 8, 9};
            for (size_t i = 0; instr.args[i].type != VM_ARG_NONE; i++) {
                if (instr.args[i].type == VM_ARG_REG) {
                    size_t cpureg = argregs[i];
                    size_t vmreg = instr.args[i].reg;
                    if (vmregs[vmreg] >= 0) {
                        instr.args[i] = (vm_arg_t) {
                            .type = VM_ARG_X64,
                            .vmreg = vmreg,
                            .x64 = vmregs[vmreg],
                        };
                    } else if (cpuregs[cpureg] < 0) {
                        cpuregs[cpureg] = vmreg;
                        vmregs[vmreg] = cpureg;
                        instr.args[i] = (vm_arg_t) {
                            .type = VM_ARG_X64,
                            .vmreg = vmreg,
                            .x64 = cpureg,
                        };
                    } else {
                        instr.args[i] = (vm_arg_t) {
                            .type = VM_ARG_X64,
                            .vmreg = -1,
                            .x64 = vm_x64_reg_alloc(vmregs, cpuregs, vmreg),
                        };
                    }
                }
            }
            break;            
        }
        case VM_IOP_MUL:
        case VM_IOP_DIV:
        case VM_IOP_MOD: {
            if (instr.args[0].type == VM_ARG_REG) {
                if (cpuregs[0] < 0) {
                    cpuregs[0] = instr.args[0].reg;
                    vmregs[instr.args[0].reg] = 0;
                    instr.args[0] = (vm_arg_t) {
                        .type = VM_ARG_X64,
                        .vmreg = instr.args[0].reg,
                        .x64 = 0,
                    };
                } else {
                    instr.args[0] = (vm_arg_t) {
                        .type = VM_ARG_X64,
                        .vmreg = instr.args[0].reg,
                        .x64 = vm_x64_reg_alloc(vmregs, cpuregs, instr.args[0].reg),
                    };
                }
            }
            if (instr.args[1].type == VM_ARG_REG) {
                instr.args[1] = (vm_arg_t) {
                    .type = VM_ARG_X64,
                    .vmreg = instr.args[1].reg,
                    .x64 = vm_x64_reg_alloc(vmregs, cpuregs, instr.args[1].reg),
                };
            }
            break;
        }
        case VM_IOP_CALL: {
            static int8_t argregs[] = {7, 6, 2, 1, 8, 9};
            instr.args[0].func->isfunc = true;
            for (size_t i = 1; instr.args[i].type != VM_ARG_NONE; i++) {
                if (instr.args[i].type == VM_ARG_REG) {
                    size_t cpureg = argregs[i-1];
                    size_t vmreg = instr.args[i].reg;
                    if (vmregs[vmreg] >= 0) {
                        instr.args[i] = (vm_arg_t) {
                            .type = VM_ARG_X64,
                            .vmreg = vmreg,
                            .x64 = vmregs[vmreg],
                        };
                    } else if (cpuregs[cpureg] < 0) {
                        cpuregs[cpureg] = vmreg;
                        vmregs[vmreg] = cpureg;
                        instr.args[i] = (vm_arg_t) {
                            .type = VM_ARG_X64,
                            .vmreg = vmreg,
                            .x64 = cpureg,
                        };
                    } else {
                        instr.args[i] = (vm_arg_t) {
                            .type = VM_ARG_X64,
                            .vmreg = -1,
                            .x64 = vm_x64_reg_alloc(vmregs, cpuregs, vmreg),
                        };
                    }
                }
            }
            break;
        }
        case VM_IOP_PRINT:
        case VM_IOP_OUT: {
            if (instr.args[0].type == VM_ARG_REG) {
                size_t cpureg = 7;
                size_t vmreg = instr.args[0].reg;
                if (vmregs[vmreg] >= 0) {
                    instr.args[0] = (vm_arg_t) {
                        .type = VM_ARG_X64,
                        .vmreg = vmreg,
                        .x64 = vmregs[vmreg],
                    };
                } else if (cpuregs[cpureg] < 0) {
                    cpuregs[cpureg] = vmreg;
                    vmregs[vmreg] = cpureg;
                    instr.args[0] = (vm_arg_t) {
                        .type = VM_ARG_X64,
                        .vmreg = vmreg,
                        .x64 = cpureg,
                    };
                } else {
                    instr.args[0] = (vm_arg_t) {
                        .type = VM_ARG_X64,
                        .vmreg = vmreg,
                        .x64 = vm_x64_reg_alloc(vmregs, cpuregs, vmreg),
                    };
                }
            }
            break;
        }
        default: {
            vm_print_instr(stdout, instr);
            printf("\n");
            __builtin_trap();
        }
        }
        block->instrs[head] = instr;
    }
    for (size_t i = 0; i < block->nargs; i++) {
        if (block->args[i].type == VM_ARG_REG) {
            size_t reg = block->args[i].reg;
            if (vmregs[reg] >= 0) {
                block->args[i] = (vm_arg_t) {
                    .type = VM_ARG_X64,
                    .vmreg = reg,
                    .x64 = vmregs[reg],
                };
            } else {
                block->args[i] = (vm_arg_t) {
                    .type = VM_ARG_X64,
                    .vmreg = reg,
                    .x64 = vm_x64_reg_alloc(vmregs, cpuregs, reg),
                };
            }
        }
    }
}

|.arch x64
|.section code

void vm_x64_comp_save(dasm_State **Dst, uint16_t save) {
    size_t count = 0;
    for (size_t i = 0; i < 16; i++) {
        if (save & (1 << i)) {
            | mov [rsp + (8 * count + 8)], Rq(i)
            count += 1;
        }
    }
}

void vm_x64_comp_unsave(dasm_State **Dst, uint16_t save) {
    size_t count = 0;
    for (size_t i = 0; i < 16; i++) {
        if (save & (1 << i)) {
            | mov Rq(i), [rsp + (8 * count + 8)]
            count += 1;
        }
    }
}

void vm_x64_block_comp(vm_x64_state_t *state, vm_block_t *block, dasm_State **Dst, int8_t *pass) {
    size_t count = 0;
    int8_t from[16];
    int8_t to[16];
    for (size_t i = 0; i < block->nargs; i++) {
        vm_arg_t arg = block->args[i];
        if (arg.type == VM_ARG_X64) {
            to[count] = arg.x64;
            from[count] = pass[i];
            if (from[count] != to[count]) {
                count += 1;
            }
        } else {
            __builtin_trap();
        }
    }
    switch (count) {
    case 0: {
        break;
    }
    case 1: {
        | mov Rq(to[0]), Rq(from[0])
        break;
    }
    case 2: {
        if (from[1] != to[0]) {
            | mov Rq(to[0]), Rq(from[0])
            | mov Rq(to[1]), Rq(from[1])
        } else {
            | mov [rsp+8], Rq(from[1])
            | mov Rq(to[0]), Rq(from[0])
            | mov Rq(to[1]), [rsp+8]
        }
        break;
    }
    default: {
        for (size_t i = 0; i + 1 < count; i++) {
            | mov [rsp+(i*8+8)], Rq(from[i])
        }
        | mov Rq(to[count-1]), Rq(from[count-1])
        for (size_t i = 0; i + 1 < count; i++) {
            | mov Rq(to[i]), [rsp+(i*8+8)]
        }
        break;
    }
    }
    if (block->label >= 0) {
        | jmp =>block->label
        return;
    }
    block->label = state->count++;
    |=>block->label:
    for (size_t instr_num = 0; instr_num < block->len; instr_num++) {
        vm_instr_t instr = block->instrs[instr_num];
        switch (instr.op) {
        case VM_IOP_NOP: {
            break;
        }
        case VM_IOP_MOVE: {
            if (instr.out.type == VM_ARG_X64) {
                if (instr.args[0].type == VM_ARG_X64) {
                    if (instr.args[0].x64 != instr.out.x64) {
                        | mov Rq(instr.out.x64), Rq(instr.args[0].x64)
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    | mov Rq(instr.out.x64), ((int32_t) (instr.args[0].num))
                } else {
                    __builtin_trap();
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_ADD: {
            if (instr.out.type == VM_ARG_X64) {
                if (instr.args[0].type == VM_ARG_X64) {
                    if (instr.args[1].type == VM_ARG_X64) {
                        if (instr.out.x64 == instr.args[0].x64) {
                            | add Rq(instr.out.x64), Rq(instr.args[1].x64)
                        } else {
                            | lea Rq(instr.out.x64), [Rq(instr.args[0].x64)+((int32_t) (instr.args[1].num))]
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        if (instr.out.x64 == instr.args[0].x64) {
                            | add Rq(instr.out.x64), ((int32_t) (instr.args[1].num))
                        } else {
                            | lea Rq(instr.out.x64), [Rq(instr.args[0].x64)+((int32_t) (instr.args[1].num))]
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_X64) {
                        if (instr.out.x64 == instr.args[1].x64) {
                            | add Rq(instr.out.x64), ((int32_t) (instr.args[0].num))
                        } else {
                            | lea Rq(instr.out.x64), [Rq(instr.args[1].x64)+((int32_t) (instr.args[0].num))]
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        | mov Rd(instr.out.x64), (((int32_t) (instr.args[0].num))+((int32_t) (instr.args[1].num)))
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_SUB: {
            if (instr.out.type == VM_ARG_X64) {
                if (instr.args[0].type == VM_ARG_X64) {
                    if (instr.args[1].type == VM_ARG_X64) {
                        if (instr.out.x64 == instr.args[0].x64) {
                            | sub Rq(instr.out.x64), ((int32_t) (instr.args[1].x64))
                        } else {
                            | lea Rq(instr.out.x64), [Rq(instr.args[0].x64)-((int32_t) (instr.args[1].x64))]
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        | lea Rq(instr.out.x64), [Rq(instr.args[0].x64)-((int32_t) (instr.args[1].num))]
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_X64) {
                        if (instr.out.x64 == instr.args[1].x64) {
                            | sub Rq(instr.out.x64), ((int32_t) (instr.args[0].num))
                            | neg Rq(instr.out.x64)
                        } else {
                            | mov Rd(instr.out.x64), ((int32_t) (instr.args[0].num))
                            | sub Rq(instr.out.x64), Rq(instr.args[1].x64)
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        | mov Rd(instr.out.x64), (((int32_t) (instr.args[0].num))-((int32_t) (instr.args[1].num)))
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_MUL: {
            if (instr.out.type == VM_ARG_X64) {
                size_t out = 0;
                if (instr.out.save & (1 << 0)) {
                    | mov [rsp+8], rax
                }
                if (instr.out.save & (1 << 2)) {
                    | mov [rsp+16], rdx
                }
                if (instr.args[0].type == VM_ARG_X64) {
                    if (instr.args[0].x64 != 0) {
                        | mov rax, Rq(instr.args[0].x64)
                    }
                    if (instr.args[1].type == VM_ARG_X64) {
                        | mul Rq(instr.args[1].x64)
                        if (instr.out.x64 != out) {
                            | mov Rq(instr.out.x64), Rq(out)
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        size_t r = 16;
                        for (size_t reg = 0; reg < 16; reg++) {
                            if (reg == 0 || reg == 2) {
                                continue;
                            }
                            if (!(instr.out.save & (1 << reg)) && vm_x64_is_clobbered[reg]) {
                                r = reg;
                                break;
                            }
                        }
                        if (r == 16) {
                            __builtin_trap();
                        }
                        | mov Rd(r), ((int32_t) (instr.args[1].num))
                        | mul Rq(r)
                        if (instr.out.x64 != out) {
                            | mov Rq(instr.out.x64), Rq(out)
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_X64) {
                        __builtin_trap();
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        __builtin_trap();
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
                if (instr.out.save & (1 << 0)) {
                    | mov rax, [rsp+8]
                }
                if (instr.out.save & (1 << 2)) {
                    | mov rdx, [rsp+16]
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_DIV:
        case VM_IOP_MOD: {
            if (instr.out.type == VM_ARG_X64) {
                size_t out = instr.op == VM_IOP_MOD ? 2 : 0;
                if (instr.out.save & (1 << 0)) {
                    | mov [rsp+8], rax
                }
                if (instr.out.save & (1 << 2)) {
                    | mov [rsp+16], rdx
                }
                if (instr.args[0].type == VM_ARG_X64) {
                    if (instr.args[0].x64 != 0) {
                        | mov rax, Rq(instr.args[0].x64)
                    }
                    | xor edx, edx
                    if (instr.args[1].type == VM_ARG_X64) {
                        | div Rq(instr.args[1].x64)
                        if (instr.out.x64 != out) {
                            | mov Rq(instr.out.x64), Rq(out)
                        }
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        size_t r = 16;
                        for (size_t reg = 0; reg < 16; reg++) {
                            if (reg == 0 || reg == 2) {
                                continue;
                            }
                            if (!(instr.out.save & (1 << reg)) && vm_x64_is_clobbered[reg]) {
                                r = reg;
                                break;
                            }
                        }
                        if (r == 16) {
                            __builtin_trap();
                        }
                        | mov Rd(r), ((int32_t) (instr.args[1].num))
                        | div Rq(r)
                        if (instr.out.x64 != out) {
                            | mov Rq(instr.out.x64), Rq(out)
                        }
                    } else {
                        __builtin_trap();
                    }
                } else if (instr.args[0].type == VM_ARG_NUM) {
                    if (instr.args[1].type == VM_ARG_X64) {
                        __builtin_trap();
                    } else if (instr.args[1].type == VM_ARG_NUM) {
                        __builtin_trap();
                    } else {
                        __builtin_trap();
                    }
                } else {
                    __builtin_trap();
                }
                if (instr.out.save & (1 << 0)) {
                    | mov rax, [rsp+8]
                }
                if (instr.out.save & (1 << 2)) {
                    | mov rdx, [rsp+16]
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_CALL: {
            vm_x64_comp_save(Dst, instr.out.save);
            static int8_t argregs[] = {7, 6, 2, 1, 8, 9};
            uint16_t save_args = 0;
            for (size_t i = 1; instr.args[i].type != VM_ARG_NONE; i++) {
                save_args |= (1 << argregs[i-1]);
                if (instr.args[i].type == VM_ARG_X64) {
                    if (instr.args[i].x64 != argregs[i-1]) {
                        | mov Rq(argregs[i-1]), Rq(instr.args[i].x64)
                    }
                } else if (instr.args[i].type == VM_ARG_NUM) {
                    | mov Rd(argregs[i-1]), ((int32_t) (instr.args[i].num))
                } else {
                    __builtin_trap();
                }
            }
            vm_x64_link_t *link = vm_malloc(sizeof(vm_x64_link_t));
            link->isfunc = true;
            link->label = state->count++;
            link->out = (void **) vm_x64_mmap(state, sizeof(void *));
            *link->out = NULL;
            link->next = state->links;
            link->block = instr.args[0].func;
            link->save = instr.out.save | save_args;
            state->links = link;
            | call qword [((int32_t) (size_t) (link->out))]
            vm_x64_comp_unsave(Dst, instr.out.save);
            if (instr.out.type == VM_ARG_X64) {
                if (instr.out.x64 != 0) {
                    | mov Rq(instr.out.x64), rax
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_OUT: {
            vm_x64_comp_save(Dst, instr.out.save);
            if (instr.args[0].type == VM_ARG_X64) {
                if (instr.args[0].x64 != 7) {
                    | mov rdi, Rq(instr.args[0].x64)
                }
            } else if (instr.args[0].type == VM_ARG_NUM) {
                | mov edi, ((int32_t) (instr.args[0].num))
            } else {
                __builtin_trap();
            }
            | mov64 rax, ((uint64_t) &vm_putchar)
            | call rax
            vm_x64_comp_unsave(Dst, instr.out.save);
            break;
        }
        case VM_IOP_PRINT: {
            vm_x64_comp_save(Dst, instr.out.save);
            if (instr.args[0].type == VM_ARG_X64) {
                if (instr.args[0].x64 != 7) {
                    | mov rdi, Rq(instr.args[0].x64)
                }
            } else if (instr.args[0].type == VM_ARG_NUM) {
                | mov edi, ((int32_t) (instr.args[0].num))
            } else {
                __builtin_trap();
            }
            if (instr.tag == VM_TAG_I64) {
                | mov64 rax, ((uint64_t) &vm_print_i64)
            } else if (instr.tag == VM_TAG_TABLE) {
                | mov64 rax, ((uint64_t) &vm_print_table)
            } else if (instr.tag == VM_TAG_NIL) {
                | mov64 rax, ((uint64_t) &vm_print_nil)
            } else {
                __builtin_trap();
            }
            | call rax
            vm_x64_comp_unsave(Dst, instr.out.save);
            break;
        }
        case VM_IOP_NEW: {
            vm_x64_comp_save(Dst, instr.out.save);
            | mov64 rax, ((uint64_t) &vm_table_new)
            | call rax
            vm_x64_comp_unsave(Dst, instr.out.save);
            if (instr.out.type == VM_ARG_X64) {
                if (instr.out.x64 != 0) {
                    | mov Rq(instr.out.x64), rax
                }
            } else if (instr.out.type != VM_ARG_NONE) {
                __builtin_trap();
            }
            break;
        }
        case VM_IOP_SET: {
            vm_x64_comp_save(Dst, instr.out.save);
            if (instr.args[0].type == VM_ARG_X64) {
                if (instr.args[0].x64 != 7) {
                    | mov rdi, Rq(instr.args[0].x64)
                }
            } else {
                __builtin_trap();
            }
            if (instr.args[1].type == VM_ARG_X64) {
                if (instr.args[1].x64 != 6) {
                    | mov rsi, Rq(instr.args[1].x64)
                }
            } else if (instr.args[1].type == VM_ARG_NUM) {
                | mov esi, ((int32_t) (instr.args[1].num))
            } else {
                __builtin_trap();
            }
            if (instr.args[2].type == VM_ARG_X64) {
                if (instr.args[2].x64 != 2) {
                    | mov rdx, Rq(instr.args[2].x64)
                }
            } else if (instr.args[2].type == VM_ARG_NUM) {
                | mov edx, ((int32_t) (instr.args[2].num))
            } else {
                __builtin_trap();
            }
            // | mov rcx, [rdi]
            // | mov eax, [rdi+0x08]
            // |1:
            // | test eax, eax
            // | jz >3
            // | sub eax, 24
            // | cmp dword [rcx+rax+0x10], (instr.args[3].tag)
            // | jne <1
            // | cmp rsi, [rcx+rax]
            // | jne <1
            // | mov [rcx+rax+0x08], rdx
            // | mov dword [rcx+rax+0x14], (instr.args[4].tag)
            // | jmp >4
            // |3:
            | mov ecx, (instr.args[3].tag)
            | mov r8d, (instr.args[4].tag)
            | mov64 rax, ((uint64_t) (&vm_table_set)) 
            | call rax
            |4:
            vm_x64_comp_unsave(Dst, instr.out.save);
            break;
        }
        default: {
            __builtin_trap(); // bad instr
        }
        }
    }
    switch (block->branch.op) {
    case VM_BOP_JUMP: {
        vm_x64_block_comp(state, block->branch.targets[0], Dst, block->branch.pass[0]);
        break;
    }
    case VM_BOP_GET: {
        uint16_t save = 0;
        for (size_t i = 0; i < block->branch.targets[0]->nargs; i++) {
            vm_arg_t arg = block->branch.targets[0]->args[i];
            if (arg.type == VM_ARG_X64) {
                save |= (1 << arg.x64);
            }
        }
        if (block->branch.out.type == VM_ARG_X64) {
            save |= (1 << block->branch.out.x64);
        }
        void **ptrs = vm_x64_mmap(state, sizeof(void *) * VM_TAG_MAX);
        for (size_t i = 1; i < VM_TAG_MAX; i++) {
            vm_x64_link_t *link = vm_malloc(sizeof(vm_x64_link_t));
            link->isfunc = false;
            link->label = state->count++;
            link->out = &ptrs[i];
            *link->out = NULL;
            link->next = state->links;
            block->branch.rtargets[i]->block->pass = block->branch.pass[0];
            link->block = block->branch.rtargets[i];
            link->save = block->branch.out.save | save;
            state->links = link;
        }
        vm_x64_comp_save(Dst, block->branch.out.save);
        if (block->branch.args[0].type == VM_ARG_X64) {
            if (block->branch.args[0].x64 != 7) {
                | mov rdi, Rq(block->branch.args[0].x64)
            }
        } else {
            __builtin_trap();
        }
        if (block->branch.args[1].type == VM_ARG_X64) {
            if (block->branch.args[1].x64 != 6) {
                | mov rsi, Rq(block->branch.args[1].x64)
            }
        } else if (block->branch.args[1].type == VM_ARG_NUM) {
            | mov esi, ((int32_t) (block->branch.args[1].num))
        } else {
            __builtin_trap();
        }
        | mov rcx, [rdi]
        | mov eax, [rdi+0x08]
        |1:
        | test eax, eax
        | jz >3
        | sub eax, 24
        | mov edx, [rcx+rax+0x10]
        | cmp edx, ((int32_t) block->branch.tag)
        | jne <1
        | cmp rsi, [rcx+rax]
        | jne <1
        for (size_t i = 1; i < VM_TAG_MAX; i++) {
            | cmp edx, i
            | jne >2
            if (block->branch.out.type == VM_ARG_X64) {
                | mov Rq(block->branch.out.x64), [rcx+rax+0x08]
            } else {
                __builtin_trap();
            }
            vm_x64_comp_unsave(Dst, block->branch.out.save);
            | jmp qword [((int32_t) (size_t) (&ptrs[i]))]
            |2:
        }
        |3:
        vm_x64_comp_unsave(Dst, block->branch.out.save);
        | jmp qword [((int32_t) (size_t) (ptrs+VM_TAG_NIL))]
        break;
    }
    case VM_BOP_BEQ:
    case VM_BOP_BLT: {
        size_t t = state->count++;
        if (block->branch.op == VM_BOP_BLT) {
            if (block->branch.args[0].type == VM_ARG_X64) {
                if (block->branch.args[1].type == VM_ARG_X64) {
                    | cmp Rq(block->branch.args[0].x64), Rq(block->branch.args[1].x64)
                    | jl =>t
                } else if (block->branch.args[1].type == VM_ARG_NUM) {
                    | cmp Rq(block->branch.args[0].x64), ((int32_t) (block->branch.args[1].num))
                    | jl =>t
                } else {
                    __builtin_trap();
                }
            } else if (block->branch.args[0].type == VM_ARG_NUM) {
                if (block->branch.args[1].type == VM_ARG_X64) {
                    | cmp Rq(block->branch.args[1].x64), ((int32_t) (block->branch.args[0].num))
                    | jnl =>t
                } else if (block->branch.args[1].type == VM_ARG_NUM) {
                    if (block->branch.args[0].num < block->branch.args[1].num) {
                        | jmp =>t
                    }
                } else {
                    __builtin_trap();
                }
            } else {
                __builtin_trap();
            }
        } else {
            if (block->branch.args[0].type == VM_ARG_X64) {
                if (block->branch.args[1].type == VM_ARG_X64) {
                    | cmp Rq(block->branch.args[0].x64), Rq(block->branch.args[1].x64)
                    | je =>t
                } else if (block->branch.args[1].type == VM_ARG_NUM) {
                    | cmp Rq(block->branch.args[0].x64), ((int32_t) (block->branch.args[1].num))
                    | je =>t
                } else {
                    __builtin_trap();
                }
            } else if (block->branch.args[0].type == VM_ARG_NUM) {
                if (block->branch.args[1].type == VM_ARG_X64) {
                    | cmp Rq(block->branch.args[1].x64), ((int32_t) (block->branch.args[0].num))
                    | je =>t
                } else if (block->branch.args[1].type == VM_ARG_NUM) {
                    if (block->branch.args[0].num == block->branch.args[1].num) {
                        | jmp =>t
                    }
                } else {
                    __builtin_trap();
                }
            } else {
                __builtin_trap();
            }
        }
        vm_x64_block_comp(state, block->branch.targets[1], Dst, block->branch.pass[1]);
        |=>t:
        vm_x64_block_comp(state, block->branch.targets[0], Dst, block->branch.pass[0]);
        break;
    }
    case VM_BOP_RET: {
        if (block->branch.args[0].type == VM_ARG_X64) {
            if (block->branch.args[0].x64 != 0) {
                | mov rax, Rq(block->branch.args[0].x64)
            }
        } else if (block->branch.args[0].type == VM_ARG_NUM) {
            | mov eax, ((int32_t) (block->branch.args[0].num))
        } else {
            __builtin_trap();
        }
        | add rsp, state->push
        | ret
        break;
    }
    case VM_BOP_EXIT: {
        | mov64 rax, ((uint64_t) (&state->exitptr))
        | mov rsp, [rax]
        | ret
        break;
    }
    default: {
        __builtin_trap(); // branch
    }
    }
}

void *vm_x64_func_block_comp(vm_x64_state_t *state, vm_rblock_t *rblock) {
    vm_block_t *cur = vm_x64_rblock_version(rblock);
    cur->isfunc = false;
    return vm_x64_func_comp(state, cur);
}

void *vm_x64_func_comp(vm_x64_state_t *state, vm_block_t *block) {
    if (block->impl != NULL) {
        return block->impl;
    }
    size_t old_count = state->count;
    size_t old_push = state->push;
    vm_x64_link_t *old_links = state->links;
    state->links = NULL;
    state->count = 0;
    state->push = 16 * 8 + 8;
    dasm_State* d = NULL;
    dasm_State** Dst = &d;
    dasm_init(Dst, DASM_MAXSECTION);
    |.globals lbl_
    void* labels[lbl__MAX];
    dasm_setupglobal(Dst, labels, lbl__MAX);
    |.actionlist act
    dasm_setup(Dst, act);
    dasm_growpc(Dst, 128);
    |.code
    |->main:
    if (state->exitptr == NULL) {
        | mov64 rax, ((uint64_t) (&state->exitptr))
        | mov [rax], rsp
    }
    vm_x64_reg_alloc_block(state, block);
    if (block->isfunc) {
        | sub rsp, state->push
        static int8_t vm_sysv_argregs[] = {7, 6, 2, 1, 8, 9};
        vm_x64_block_comp(state, block, Dst, vm_sysv_argregs);
    } else {
        vm_x64_block_comp(state, block, Dst, block->pass);
    }
    for (vm_x64_link_t *link = state->links; link != NULL; link = link->next) {
        |=>link->label:
        if (link->isfunc) {
            size_t push = 8 * 8;
            | sub rsp, push
            size_t off1 = 8;
            for (size_t i = 0; i < 16; i++) {
                if (link->save & (1 << i)) {
                    | mov [rsp+(off1)], Rq(i)
                    off1 += 8;
                }
            }
            | mov64 rdi, ((uint64_t) (state))
            | mov64 rsi, ((uint64_t) (link->block))
            | mov64 rax, ((uint64_t) (vm_x64_func_comp))
            | call rax
            size_t off2 = 8;
            for (size_t i = 0; i < 16; i++) {
                if (link->save & (1 << i)) {
                    | mov Rq(i), [rsp+(off2)]
                    off2 += 8;
                }
            }
            | mov [((int32_t) (size_t) (link->out))], rax
            | add rsp, push
            | jmp rax
        } else {
            size_t push = 8 * 8;
            | sub rsp, push
            size_t off1 = 8;
            for (size_t i = 0; i < 16; i++) {
                if (link->save & (1 << i)) {
                    | mov [rsp+(off1)], Rq(i)
                    off1 += 8;
                }
            }
            | mov64 rdi, ((uint64_t) (state))
            | mov64 rsi, ((uint64_t) (link->block))
            | mov64 rax, ((uint64_t) (vm_x64_func_block_comp))
            | call rax
            size_t off2 = 8;
            for (size_t i = 0; i < 16; i++) {
                if (link->save & (1 << i)) {
                    | mov Rq(i), [rsp+(off2)]
                    off2 += 8;
                }
            }
            | mov [((int32_t) (size_t) (link->out))], rax
            | add rsp, push
            | jmp rax
        }
    }
    vm_x64_encode(state, Dst);
    void *fn = labels[lbl_main];
    block->impl = fn;
    state->count = old_count;
    state->push = old_push;
    state->links = old_links;
    // printf("fn = %p\n", fn);
    return fn;
}

void *vm_x64_full_comp(vm_x64_state_t *state, vm_block_t *block) {
    vm_tags_t *regs = vm_rblock_regs_empty(256);
    vm_rblock_t *rblock = vm_rblock_new(block, regs);
    vm_block_t *cur = vm_x64_rblock_version(rblock);
    cur->isfunc = true;
    return vm_x64_func_comp(state, cur);
}

void vm_x64_run(vm_block_t *block) {
    vm_x64_state_t state = (vm_x64_state_t){0};
    void *code = vm_x64_full_comp(&state, block);
    void (*fn)(void) = code;
    fn();
}
