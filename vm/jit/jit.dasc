
#include <stdio.h>
#include <stdlib.h>
#include "../../dynasm/dasm_proto.h"
#include "../../dynasm/dasm_x86.h"

#if defined(VM_MINGW)
#include <windows.h>
#elif defined(_WIN32)
#include <Windows.h>
#else
#include <sys/mman.h>
#if !defined(MAP_ANONYMOUS) && defined(MAP_ANON)
#define MAP_ANONYMOUS MAP_ANON
#endif
#endif
#define VM_NREGS 256

#include "./jit.h"

static void vm_jit_rblock_single(vm_jit_state_t *state, dasm_State **dst, vm_rblock_t *rnext);
static void *vm_jit_rblock(vm_jit_state_t *state, vm_rblock_t *rblock);

|.arch x64

#define rArg0 7
#define rArg1 6
#define rArg2 2
#define rArg3 1
#define rArg4 8
#define rArg5 9
// its my abi, mom!
#define rArg6 10
#define rArg7 11
#define rArg8 12

|.define RAX, 0
|.define RCX, 1
|.define RDX, 2
|.define RBX, 3
|.define RSP, 4
|.define RBP, 5
|.define RSI, 6
|.define RDI, 7
|.define R8, 8
|.define R9, 9
|.define R10, 10
|.define R11, 11
|.define R12, 12
|.define R13, 13
|.define R14, 14
|.define R15, 15

|.macro invoke, func
|| {
    || void *ptr = (void*) (func);
    | mov64 rax, ((uint64_t) (ptr))
    | call rax
|| }
|.endmacro

|.macro vmjump_defer, arg1
|| {
    ||vm_rblock_t *block = arg1;
    ||void **bit = vm_malloc(sizeof(void *));
    ||*bit = NULL;
    | mov64 rcx, ((uint64_t) (bit))
    | mov rax, [rcx]
    | test rax, rax
    |jnz >9
    | mov64 Rq(rArg0), ((uint64_t) state)
    | mov64 Rq(rArg1), ((uint64_t) block)
    | invoke vm_jit_rblock
    | mov64 rcx, ((uint64_t) (bit))
    | mov [rcx], rax
    |9:
    | jmp rax
|| }
|.endmacro

|.if 0
|.macro vmjump, arg1
| vmjump_defer arg1
|| {
    ||vm_rblock_t *rblock = arg1;
    ||bool todo = true;
    ||for (size_t i = 0; i < state->depth; i++) {
        ||vm_rblock_t *found = state->stack[i];
        ||if (rblock->block == found->block && rblock->start == found->start) {
            || todo = false;
            || for (size_t j = 0; j < rblock->block->nargs; j++) {
                ||size_t regno = rblock->block->args[j];
                ||if (rblock->regs->tags[regno] != found->regs->tags[regno]) {
                    ||todo = true;
                    ||break;
                ||}
            || }   
            || if (!todo) {
                |jmp =>i
                ||break;
            ||}
        ||}
    ||}
    ||if (todo) {
        ||if (state->depth < 16) {
            || vm_jit_rblock_single(state, Dst, rblock);
        ||} else {
            | vmjump_defer rblock
        ||}
    ||}
|| }
|.endmacro
|.else
|.macro vmjump, arg1
| vmjump_defer arg1
|.endmacro
|.endif

|.macro invoke_code, func
    || {
    || void *ptr = (void*) (func);
    | mov64 rax, ((uint64_t) (ptr))
    | call rax
    || }
|.endmacro

|.macro vmcall, arg1
|| {
    ||vm_rblock_t *block = arg1;
    ||void **bit = vm_malloc(sizeof(void *));
    ||*bit = NULL;
    | mov64 rcx, ((uint64_t) (bit))
    | mov rax, [rcx]
    | test rax, rax
    |jnz >9
    | mov64 Rq(rArg0), ((uint64_t) state)
    | mov64 Rq(rArg1), ((uint64_t) block)
    | invoke vm_jit_rblock
    | mov64 rcx, ((uint64_t) (bit))
    | mov [rcx], rax
    |9:
    | call rax
|| }
|.endmacro

|.macro vmload64, arg1, arg2
|| {
    || vm_arg_t arg = arg2;
    || if (arg.type == VM_ARG_REG) {
        | mov Rq(arg1), [rsp + (8 * arg.reg + 8)]
    || } else if (arg.type == VM_ARG_NUM) {
        || int64_t n = (int64_t) arg.num;
        || int32_t t = (int32_t) n;
        || if (n == (int64_t) t) {
            | mov Rd(arg1), n
        || } else {
            | mov64 Rq(arg1), n
        || }
    ||}
|| }
|.endmacro

|.macro vmload8, arg1, arg2
|| {
    || vm_arg_t arg = arg2;
    || if (arg.type == VM_ARG_REG) {
        | mov Rb(arg1), [rsp + (8 * arg.reg + 8)]
    || } else if (arg.type == VM_ARG_NUM) {
        || int8_t n = (int8_t) arg.num;
        | mov Rb(arg1), n
    ||}
|| }
|.endmacro

|.macro vmload16, arg1, arg2
|| {
    || vm_arg_t arg = arg2;
    || if (arg.type == VM_ARG_REG) {
        | mov Rw(arg1), [rsp + (8 * arg.reg + 8)]
    || } else if (arg.type == VM_ARG_NUM) {
        || int16_t n = (int16_t) arg.num;
        | mov Rw(arg1), n
    ||}
|| }
|.endmacro

|.macro vmload32, arg1, arg2
|| {
    || vm_arg_t arg = arg2;
    || if (arg.type == VM_ARG_REG) {
        | mov Rq(arg1), [rsp + (8 * arg.reg + 8)]
    || } else if (arg.type == VM_ARG_NUM) {
        || int32_t n = (int32_t) arg.num;
        | mov Rd(arg1), n
    ||}
|| }
|.endmacro

|.macro vmstore64, arg1, arg2
|| {
    | mov [rsp + (8 * (arg1).reg + 8)], Rq(arg2)
|| }
|.endmacro

|.macro vmstore8, arg1, arg2
|| {
    | mov [rsp + (8 * (arg1).reg + 8)], Rb(arg2)
|| }
|.endmacro

|.macro vmstore16, arg1, arg2
|| {
    | mov [rsp + (8 * (arg1).reg + 8)], Rw(arg2)
|| }
|.endmacro

|.macro vmstore32, arg1, arg2
|| {
    | mov [rsp + (8 * (arg1).reg + 8)], Rd(arg2)
|| }
|.endmacro

|.macro check, instr, size, av1, av2
|| {
    || vm_arg_t arg1 = av1;
    || vm_arg_t arg2 = av2;
    || if (arg2.type == VM_ARG_NUM) {
        | vmload..size RAX, arg1
        || switch (size) {
        || case 8: { 
            | instr al, ((int8_t) arg2.num)
            || break;
        || }
        || case 16: {
            | instr ax, ((int16_t) arg2.num)
            || break;
        || }
        || case 32: {
            | instr eax, ((int32_t) arg2.num)
            || break;
        || }
        || case 64: {
            || int64_t n = (int64_t) arg2.num;
            || int32_t t = (int32_t) n;
            || if (n == (int64_t) t) {
                | instr rax, t
            || } else {
                | mov64 rcx, n
                | instr rax, rcx
            || }
            || break;
        || }
        || }
    || } else {
        | vmload..size RAX, arg1
        | vmload..size RCX, arg2
        || switch (size) {
        || case 8: {
            | instr al, cl
            || break;
        || }
        || case 16: {
            | instr ax, cx
            || break;
        || }
        || case 32: {
            | instr eax, ecx
            || break;
        || }
        || case 64: {
            | instr rax, rcx
            || break;
        || }
        || }
    || }
|| }
|.endmacro

|.macro math, instr, size, ov, av1, av2
|| {
    || vm_arg_t out = ov;
    || vm_arg_t arg1 = av1;
    || vm_arg_t arg2 = av2;
    || if (arg1.type == VM_ARG_REG && out.reg == arg1.reg) {
        || if (arg2.type == VM_ARG_NUM) {
            || switch (size) {
            || case 8: { 
                | instr byte [rsp + (8 * out.reg + 8)], ((int8_t) arg2.num)
                || break;
            || }
            || case 16: {
                | instr word [rsp + (8 * out.reg + 8)], ((int16_t) arg2.num)
                || break;
            || }
            || case 32: {
                | instr dword [rsp + (8 * out.reg + 8)], ((int32_t) arg2.num)
                || break;
            || }
            || case 64: {
                || int64_t n = (int64_t) arg2.num;
                || int32_t t = (int32_t) n;
                || if (n == (int64_t) t) {
                    | instr qword [rsp + (8 * out.reg + 8)], t
                || } else {
                    | mov64 rax, n
                    | instr qword [rsp + (8 * out.reg + 8)], rax
                || }
                || break;
            || }
            || }
        || } else {
            | vmload..size RAX, arg2
            || switch (size) {
            || case 8: { 
                | instr byte [rsp + (8 * out.reg + 8)], al
                || break;
            || }
            || case 16: {
                | instr word [rsp + (8 * out.reg + 8)], ax
                || break;
            || }
            || case 32: {
                | instr dword [rsp + (8 * out.reg + 8)], eax
                || break;
            || }
            || case 64: {
                | instr qword [rsp + (8 * out.reg + 8)], rax
                || break;
            || }
            || }
        || }
    || } else {
        || if (arg2.type == VM_ARG_NUM) {
            | vmload..size RAX, arg1
            || switch (size) {
            || case 8: { 
                | instr al, ((int8_t) arg2.num)
                || break;
            || }
            || case 16: {
                | instr ax, ((int16_t) arg2.num)
                || break;
            || }
            || case 32: {
                | instr eax, ((int32_t) arg2.num)
                || break;
            || }
            || case 64: {
                || int64_t n = (int64_t) arg2.num;
                || int32_t t = (int32_t) n;
                || if (n == (int64_t) t) {
                    | instr rax, t
                || } else {
                    | mov64 rcx, n
                    | instr rax, rcx
                || }
                || break;
            || }
            || }
            | vmstore..size out, RAX
        || } else {
            | vmload..size RAX, arg1
            | vmload..size RCX, arg2
            || switch (size) {
            || case 8: {
                | instr al, cl
                || break;
            || }
            || case 16: {
                | instr ax, cx
                || break;
            || }
            || case 32: {
                | instr eax, ecx
                || break;
            || }
            || case 64: {
                | instr rax, rcx
                || break;
            || }
            || }
            | vmstore..size out, RAX
        || }
    || }
|| }
|.endmacro

ptrdiff_t write(int fd, const void *buf, size_t count);

void vm_jit_putchar(int c) {
    printf("%c", c);
}

#if 1
static void* vm_jit_encode(vm_jit_state_t *state, dasm_State** d)
{
    size_t size;
    dasm_link(d, &size);
#ifdef _WIN32
    void* buf = VirtualAlloc(0, size, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE);
#else
    vm_jit_mmap_t *map = NULL;
    for (size_t i = 0; i < state->mapbuf.len; i++) {
        vm_jit_mmap_t *cur = &state->mapbuf.mmaps[state->mapbuf.len - i - 1];
        if (cur->used + size <= cur->alloc) {
            map = cur;
            break;
        }
    }
    // printf("%p / %zu", map, state->mapbuf.len);
    void *buf = NULL;
    if (map == NULL) {
        size_t blocks = 1;
        if (state->mapbuf.len < 12) {
            blocks = 1 << state->mapbuf.len;
        } else {
            blocks = 1 << 12;
        }
        size_t minsize = 4096 * blocks;
        size_t next_index = state->mapbuf.len + 1;
        if (next_index >= state->mapbuf.alloc) {
            state->mapbuf.alloc += next_index * 2;
            state->mapbuf.mmaps = vm_realloc(state->mapbuf.mmaps, sizeof(vm_jit_mmap_t) * state->mapbuf.alloc);
        }
        if (size < minsize) {
            map = &state->mapbuf.mmaps[next_index - 1];
            map->alloc = minsize;
            state->mapbuf.len = next_index;
            map->mem = mmap(0, map->alloc, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
            map->used = size;
            buf = map->mem;
        } else {
            buf = mmap(0, map->alloc, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
        }
    } else {
        buf = (void *) (((size_t) (map->mem)) + map->used);
        map->used += size;
    }
    
#endif
    dasm_encode(d, buf);
#ifdef _WIN32
    DWORD dwOld;
    VirtualProtect(buf, size, PAGE_EXECUTE_READ, &dwOld);
#else
    // mprotect(map->mem, map->alloc, PROT_READ | PROT_EXEC);
#endif
    // char chrs[256];
    // sprintf(chrs, "%p.bin", buf);
    // // static FILE *f = NULL;
    // FILE *f = NULL;
    // if (f == NULL) {
    //     f = fopen(chrs, "wb");
    // }
    // fwrite(buf, size, 1, f);
    // fclose(f);
    return buf;
}
#else
static void* vm_jit_encode(vm_jit_state_t *state, dasm_State** d)
{
    (void)state;
    size_t sz;
    void* buf;
    dasm_link(d, &sz);
#ifdef _WIN32
    buf = VirtualAlloc(0, sz, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE);
#else
    buf = mmap(0, sz, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
#endif
    dasm_encode(d, buf);
#ifdef _WIN32
    DWORD dwOld;
    VirtualProtect(buf, sz, PAGE_EXECUTE_READ, &dwOld);
#else
    mprotect(buf, sz, PROT_READ | PROT_EXEC);
#endif
    // char chrs[256];
    // sprintf(chrs, "%p.bin", buf);
    // // static FILE *f = NULL;
    // FILE *f = NULL;
    // if (f == NULL) {
    //     f = fopen(chrs, "wb");
    // }
    // fwrite(buf, sz, 1, f);
    // fclose(f);
    return buf;
}
#endif

#define VM_PUSH(n) (8 * (n | 1))

static void vm_jit_rblock_single(vm_jit_state_t *state, dasm_State **Dst, vm_rblock_t *rnext) {
    |=>state->depth:
    state->stack[state->depth++] = rnext;
    for (size_t ninstr = rnext->start; ninstr < rnext->block->len; ninstr++) {
        vm_instr_t instr = vm_rblock_type_specialize_instr(rnext->regs, rnext->block->instrs[ninstr]);
        if (!vm_rblock_type_check_instr(rnext->regs, instr)) __builtin_trap();
        switch (instr.op) {
        case VM_IOP_NOP: {
            break;
        }
        case VM_IOP_MOVE: {
            if (instr.args[0].type == VM_ARG_NUM) {
                int64_t n = instr.args[0].num;
                switch (instr.tag) {
                case VM_TAG_I8:
                case VM_TAG_U8:{
                    | mov byte [rsp + (8 * instr.out.reg + 8)], ((int8_t) n)
                    break;
                }
                case VM_TAG_I16:
                case VM_TAG_U16: {
                    | mov word [rsp + (8 * instr.out.reg + 8)], ((int16_t) n)
                    break;
                }
                case VM_TAG_I32:
                case VM_TAG_U32: {
                    | mov dword [rsp + (8 * instr.out.reg + 8)], ((int32_t) n)
                    break;
                }
                case VM_TAG_I64:
                case VM_TAG_U64: {
                    int32_t t = (int64_t) n;
                    if (n == (int64_t) t) {
                        | mov qword [rsp + (8 * instr.out.reg + 8)], n
                    } else {
                        | mov64 rax, n
                        | mov qword [rsp + (8 * instr.out.reg + 8)], rax
                    }
                    break;
                }
                }
            } else if (instr.args[0].type == VM_ARG_REG) {
                switch (instr.tag) {
                case VM_TAG_I8:
                case VM_TAG_U8:{
                    | vmload8 RAX, instr.args[0]
                    | vmstore8 instr.out, RAX
                    break;
                }
                case VM_TAG_I16:
                case VM_TAG_U16: {
                    | vmload16 RAX, instr.args[0]
                    | vmstore16 instr.out, RAX
                    break;
                }
                case VM_TAG_I32:
                case VM_TAG_U32: {
                    | vmload32 RAX, instr.args[0]
                    | vmstore32 instr.out, RAX
                    break;
                }
                case VM_TAG_I64:
                case VM_TAG_U64: {
                    | vmload64 RAX, instr.args[0]
                    | vmstore64 instr.out, RAX
                    break;
                }
                }
            }
            // | vmload64 RAX, instr.args[0]
            // | vmstore64 instr.out, RAX
            break;
        }
        case VM_IOP_CAST: {
            break;
        }
        case VM_IOP_ADD: {
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8:{
                | vmload8 RAX, instr.args[0]
                | vmload8 RCX, instr.args[1]
                | add al, cl
                | vmstore8 instr.out, RAX
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16:{
                | vmload16 RAX, instr.args[0]
                | vmload16 RCX, instr.args[1]
                | add ax, cx
                | vmstore16 instr.out, RAX
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                | vmload32 RAX, instr.args[0]
                | vmload32 RCX, instr.args[1]
                | add eax, ecx
                | vmstore32 instr.out, RAX
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                | vmload64 RAX, instr.args[0]
                | vmload64 RCX, instr.args[1]
                | add rax, rcx
                | vmstore64 instr.out, RAX
                break;
            }
            }
            break;
        }
        case VM_IOP_SUB: {
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8:{
                | vmload8 RAX, instr.args[0]
                | vmload8 RCX, instr.args[1]
                | sub al, cl
                | vmstore8 instr.out, RAX
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16:{
                | vmload16 RAX, instr.args[0]
                | vmload16 RCX, instr.args[1]
                | sub ax, cx
                | vmstore16 instr.out, RAX
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                | vmload32 RAX, instr.args[0]
                | vmload32 RCX, instr.args[1]
                | sub eax, ecx
                | vmstore32 instr.out, RAX
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                | vmload64 RAX, instr.args[0]
                | vmload64 RCX, instr.args[1]
                | sub rax, rcx
                | vmstore64 instr.out, RAX
                break;
            }
            }
            break;
        }
        case VM_IOP_MUL: {
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8: {
                | xor ax, ax
                | vmload8 RAX, instr.args[0]
                | vmload8 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I8) {
                    | imul cl
                } else {
                    | mul cl
                }
                | vmstore8 instr.out, RAX
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16: {
                | vmload16 RAX, instr.args[0]
                | vmload16 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I16) {
                    | imul cx
                } else {
                    | mul cx
                }
                | vmstore16 instr.out, RAX
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                | vmload32 RAX, instr.args[0]
                | vmload32 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I32) {
                    | imul ecx
                } else {
                    | mul ecx
                }
                | vmstore32 instr.out, RAX
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                | vmload64 RAX, instr.args[0]
                | vmload64 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I64) {
                    | imul rcx
                } else {
                    | mul rcx
                }
                | vmstore64 instr.out, RAX
                break;
            }
            }
            break;
        }
        case VM_IOP_DIV: {
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8: {
                | xor ax, ax
                | vmload8 RAX, instr.args[0]
                | vmload8 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I8) {
                    | idiv cl
                } else {
                    | div cl
                }
                | vmstore8 instr.out, RAX
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16: {
                | xor dx, dx
                | vmload16 RAX, instr.args[0]
                | vmload16 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I16) {
                    | idiv cx
                } else {
                    | div cx
                }
                | vmstore16 instr.out, RAX
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                | xor edx, edx
                | vmload32 RAX, instr.args[0]
                | vmload32 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I32) {
                    | idiv ecx
                } else {
                    | div ecx
                }
                | vmstore32 instr.out, RAX
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                | xor edx, edx
                | vmload64 RAX, instr.args[0]
                | vmload64 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I64) {
                    | idiv rcx
                } else {
                    | div rcx
                }
                | vmstore64 instr.out, RAX
                break;
            }
            }
            break;
        }
        case VM_IOP_MOD: {
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8: {
                | xor ax, ax
                | vmload8 RAX, instr.args[0]
                | vmload8 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I8) {
                    | idiv cl
                } else {
                    | div cl
                }
                | mov dl, ah
                | vmstore8 instr.out, RDX
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16: {
                | xor dx, dx
                | vmload16 RAX, instr.args[0]
                | vmload16 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I16) {
                    | idiv cx
                } else {
                    | div cx
                }
                | vmstore16 instr.out, RDX
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                | xor edx, edx
                | vmload32 RAX, instr.args[0]
                | vmload32 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I32) {
                    | idiv ecx
                } else {
                    | div ecx
                }
                | vmstore32 instr.out, RDX
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                | xor edx, edx
                | vmload64 RAX, instr.args[0]
                | vmload64 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I64) {
                    | idiv rcx
                } else {
                    | div rcx
                }
                | vmstore64 instr.out, RDX
                break;
            }
            }
            break;
        }
        case VM_IOP_CALL: {
            if (instr.args[0].type == VM_ARG_FUNC) {
                vm_tags_t *argtypes = vm_rblock_regs_empty(VM_NREGS);
                for (size_t i = 1; instr.args[i].type != VM_ARG_NONE; i++) {
                    argtypes->tags[i] = rnext->regs->tags[instr.args[i].reg];
                }
                vm_rblock_t *func = vm_rblock_new(instr.args[0].func, argtypes);
                func->isfunc = true;
                for (int32_t i = 1; instr.args[i].type != VM_ARG_NONE; i++) {
                    int32_t offset = VM_PUSH(VM_NREGS) + 8 - (8 * i + 8);
                    switch (rnext->regs->tags[instr.args[i].reg]) {
                        case VM_TAG_I8:
                        case VM_TAG_U8: {
                            | vmload8 RAX, instr.args[i] 
                            | mov byte [rsp - (offset)], al
                            break;
                        }
                        case VM_TAG_I16:
                        case VM_TAG_U16: {
                            | vmload16 RAX, instr.args[i] 
                            | mov word [rsp - (offset)], ax
                            break;
                        }
                        case VM_TAG_I32:
                        case VM_TAG_U32: {
                            | vmload32 RAX, instr.args[i] 
                            | mov dword [rsp - (offset)], eax
                            break;
                        }
                        case VM_TAG_I64:
                        case VM_TAG_U64: {
                            | vmload64 RAX, instr.args[i] 
                            | mov qword [rsp - (offset)], rax
                            break;
                        }
                    }
                }
                if (state->opt_defer_call) {
                    | vmcall func
                } else {
                    void *code = vm_jit_rblock(state, func);
                    | invoke_code code
                }
                | vmstore64 instr.out, RAX
            }
            break;
        }
        case VM_IOP_OUT: {
            | xor Rd(rArg0), Rd(rArg0)
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8: {
                | vmload8 rArg0, instr.args[0]
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16: {
                | vmload16 rArg0, instr.args[0]
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                | vmload32 rArg0, instr.args[0]
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                | vmload64 rArg0, instr.args[0]
                break;
            }
            }
            | invoke vm_jit_putchar
            break;
        }
        case VM_IOP_IN: {
            printf("IN\n");
            break;
        }
        case VM_IOP_BNOT: {
            break;
        }
        case VM_IOP_BOR: {
            break;
        }
        case VM_IOP_BAND: {
            break;
        }
        case VM_IOP_BXOR: {
            break;
        }
        case VM_IOP_BSHL: {
            break;
        }
        case VM_IOP_BSHR: {
            break;
        }
        }
        if (instr.out.type == VM_ARG_REG) {
            rnext->regs->tags[instr.out.reg] = instr.tag;
        }
    }
    vm_branch_t branch = vm_rblock_type_specialize_branch(rnext->regs, rnext->block->branch);
    if (!vm_rblock_type_check_branch(rnext->regs, branch)) __builtin_trap();
    switch (branch.op) {
    case VM_BOP_EXIT: {
        break;
    }
    case VM_BOP_RET: {
        break;
    }
    case VM_BOP_JUMP: {
        if (rnext->targets[0] == NULL) {
            rnext->targets[0] = vm_rblock_new(branch.targets[0], rnext->regs);
        }
        break;
    }
    case VM_BOP_BB: {
        if (rnext->targets[0] == NULL) {
            rnext->targets[0] = vm_rblock_new(branch.targets[0], rnext->regs);
        }
        if (rnext->targets[1] == NULL) {
            rnext->targets[1] = vm_rblock_new(branch.targets[1], rnext->regs);
        }
        break;
    }
    case VM_BOP_BEQ: {
        if (rnext->targets[0] == NULL) {
            rnext->targets[0] = vm_rblock_new(branch.targets[0], rnext->regs);
        }
        if (rnext->targets[1] == NULL) {
            rnext->targets[1] = vm_rblock_new(branch.targets[1], rnext->regs);
        }
        break;
    }
    case VM_BOP_BLT: {
        if (rnext->targets[0] == NULL) {
            rnext->targets[0] = vm_rblock_new(branch.targets[0], rnext->regs);
        }
        if (rnext->targets[1] == NULL) {
            rnext->targets[1] = vm_rblock_new(branch.targets[1], rnext->regs);
        }
        break;
    }
    }
    switch (branch.op) {
    case VM_BOP_EXIT: {
        | mov64 rax, ((uint64_t) &state->exitptr)
        | mov rsp, [rax]
        | ret
        // | xor Rd(rArg0), Rd(rArg0)
        // | invoke exit
        break;
    }
    case VM_BOP_RET: {
        switch (branch.tag) {
        case VM_TAG_I8:
        case VM_TAG_U8: {
            | vmload8 RAX, branch.args[0]
            break;
        }
        case VM_TAG_I16:
        case VM_TAG_U16: {
            | vmload16 RAX, branch.args[0]
            break;
        }
        case VM_TAG_I32:
        case VM_TAG_U32: {
            | vmload32 RAX, branch.args[0]
            break;
        }
        case VM_TAG_I64:
        case VM_TAG_U64: {
            | vmload64 RAX, branch.args[0]
            break;
        }
        }
        | add rsp, VM_PUSH(VM_NREGS)
        | ret
        break;
    }
    case VM_BOP_JUMP: {
        | vmjump rnext->targets[0]
        break;
    }
    case VM_BOP_BB: {
        switch (branch.tag) {
        case VM_TAG_I8:
        case VM_TAG_U8: {
            | vmload8 RAX, branch.args[0]
            | test al, al
            break;
        }
        case VM_TAG_I16:
        case VM_TAG_U16: {
            | vmload16 RAX, branch.args[0]
            | test ax, ax
            break;
        }
        case VM_TAG_I32:
        case VM_TAG_U32: {
            | vmload32 RAX, branch.args[0]
            | test eax, eax
            break;
        }
        case VM_TAG_I64:
        case VM_TAG_U64: {
            | vmload64 RAX, branch.args[0]
            | test rax, rax
            break;
        }
        }
        | jnz >1
        | vmjump rnext->targets[1]
        |1:
        | vmjump rnext->targets[0]
        break;
    }
    case VM_BOP_BEQ: {
        switch (branch.tag) {
        case VM_TAG_I8:
        case VM_TAG_U8: {
            | check cmp, 8, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I16:
        case VM_TAG_U16: {
            | check cmp, 16, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I32:
        case VM_TAG_U32: {
            | check cmp, 32, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I64:
        case VM_TAG_U64: {
            | check cmp, 64, (branch.args[0]), (branch.args[1])
            break;
        }
        }
        | je >1
        | vmjump rnext->targets[1]
        |1:
        | vmjump rnext->targets[0]
        break;
    }
    case VM_BOP_BLT: {
        switch (branch.tag) {
        case VM_TAG_I8:
        case VM_TAG_U8: {
            | check cmp, 8, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I16:
        case VM_TAG_U16: {
            | check cmp, 16, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I32:
        case VM_TAG_U32: {
            | check cmp, 32, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I64:
        case VM_TAG_U64: {
            | check cmp, 64, (branch.args[0]), (branch.args[1])
            break;
        }
        }
        switch (branch.tag) {
        case VM_TAG_I8:
        case VM_TAG_I16:
        case VM_TAG_I32:
        case VM_TAG_I64: {
            | jl >1
            break;
        }
        case VM_TAG_U8:
        case VM_TAG_U16:
        case VM_TAG_U32:
        case VM_TAG_U64: {
            | jb >1
            break;
        }
        }
        | vmjump rnext->targets[1]
        |1:
        | vmjump rnext->targets[0]
        break;
    }
    }
    // state->depth -= 1;
}

#define Dst (&d)

static void *vm_jit_rblock(vm_jit_state_t *state, vm_rblock_t *rblock) {
    size_t old_depth = state->depth;
    vm_rblock_t **old_stack = state->stack;
    state->depth = 0;
    state->stack = vm_malloc(sizeof(vm_rblock_t *) * 16);
    size_t count = state->count++;
    static uint8_t ccregs[] = { rArg0, rArg1, rArg2, rArg3, rArg4, rArg5, rArg6, rArg7, rArg8 };
    void *cached = vm_cache_get(&rblock->block->cache, rblock);
    if (cached != NULL) {
        return cached;
    }
    dasm_State* d;
    |.section code
    dasm_init(&d, DASM_MAXSECTION);
    |.globals lbl_
    void* labels[lbl__MAX];
    dasm_setupglobal(&d, labels, lbl__MAX);
    |.actionlist act
    dasm_setup(&d, act);
    dasm_growpc(&d, 16);
    |.code
    |->main:
    if (count == 0) {
        | mov64 rax, ((uint64_t) &state->exitptr)
        | mov [rax], rsp
    }
    if (rblock->isfunc) {
        | sub rsp, VM_PUSH(VM_NREGS)
    }
    size_t nfuncs = 0;
    vm_tags_t *types = vm_rblock_regs_dup(rblock->regs, VM_NREGS);
    vm_rblock_t *rnext = vm_rblock_new(rblock->block, types);
    rnext->start = rblock->start;
    size_t label = state->depth++;
    |=>label:
    state->stack[label] = rnext;
    rnext->block->mark = true;
    vm_jit_rblock_single(state, &d, rnext);
    rnext->block->mark = false;
    vm_jit_encode(state, &d);
    dasm_free(&d);
    void *fn = labels[lbl_main];
    vm_cache_set(&rblock->block->cache, rnext, fn);
    state->depth = old_depth;
    state->stack = old_stack;
    return fn;
}

vm_jit_state_t *vm_jit_state_new(void) {
    vm_jit_state_t *ret = vm_malloc(sizeof(vm_jit_state_t));
    *ret = (vm_jit_state_t) {0};
    return ret;
}

void vm_jit_state_free(vm_jit_state_t *state) {
    vm_free(state);
}

void vm_jit_run(void *state_ptr, vm_block_t *block) {
    vm_jit_state_t *state = state_ptr;
    vm_rblock_t *rblock = vm_rblock_new(block, vm_rblock_regs_empty(block->nregs));
    rblock->isfunc = true;
    size_t(*fn)(void) = vm_jit_rblock(state, rblock);
    fn();
    state->count = 0;
}
