
#include <stdio.h>
#include <stdlib.h>
#include "../../dynasm/dasm_proto.h"
#include "../../dynasm/dasm_x86.h"

#if defined(VM_MINGW)
#include <windows.h>
#elif defined(_WIN32)
#include <Windows.h>
#else
#include <sys/mman.h>
#if !defined(MAP_ANONYMOUS) && defined(MAP_ANON)
#define MAP_ANONYMOUS MAP_ANON
#endif
#endif
#define VM_NREGS 256

#include "jit.h"

static void vm_jit_rblock_single(vm_jit_state_t *state, dasm_State **dst, vm_rblock_t *rnext);
static void *vm_jit_rblock(vm_jit_state_t *state, vm_rblock_t *rblock, bool isfunc);

|.arch x64

#define RAX 0
#define RCX 1
#define RDX 2
#define RBX 3
#define RSP 4
#define RBP 5
#define RSI 6
#define RDI 7
#define R8 8
#define R9 9
#define R10 10
#define R11 11
#define R12 12
#define R13 13
#define R14 14
#define R15 15

#define rArg0 RDI
#define rArg1 RSI
#define rArg2 RDX
#define rArg3 RCX
#define rArg4 R8
#define rArg5 R9

|.macro mov32q64, rno, num
||{
    ||size_t reg = (rno);
    ||uint64_t v64 = (uint64_t) (num);
    ||uint64_t v32 = (uint32_t) (v64);
    ||if ((uint64_t) v32 == v64) {
        |mov Rd(reg), v32
    ||} else {
        |mov64 Rq(reg), v64
    ||}
||}
|.endmacro

|.macro regsave
| mov [rsp+8], r8
| mov [rsp+16], r9
| mov [rsp+24], r10
| mov [rsp+32], r11
|.endmacro 

|.macro regload
| mov r8, [rsp+8]
| mov r9, [rsp+16]
| mov r10, [rsp+24]
| mov r11, [rsp+32]
|.endmacro 

|.macro invoke, func
|| {
    || void *ptr = (void*) (func);
    | mov32q64 RAX, ((uint64_t) (ptr))
    | regsave
    | call rax
    | regload
|| }
|.endmacro

|.macro vmjump, arg1
|| {
    ||vm_rblock_t *block = arg1;
    ||block->isfunc = false;
    ||void *got = vm_cache_get(&block->block->cache, block);
    ||if (got != NULL) {
        ||rnext->comps += block->comps;
        | mov32q64 RAX, ((uint64_t) (got))
        | jmp rax
    ||} else if (!block->block->mark) {
        ||got = vm_jit_rblock(state, block, false);
        ||rnext->comps += block->comps;
        | mov32q64 RAX, ((uint64_t) (got))
        | jmp rax
    ||} else {
        ||rnext->comps += 1;
        ||void **bit = vm_malloc(sizeof(void *));
        ||*bit = NULL;
        | mov32q64 RCX, ((uint64_t) (bit))
        | mov rax, [rcx]
        | test rax, rax
        |jnz >9
        | mov32q64 rArg0, ((uint64_t) state)
        | mov32q64 rArg1, ((uint64_t) block)
        | mov Rd(rArg2), 0
        | invoke vm_jit_rblock
        | mov32q64 RCX, ((uint64_t) (bit))
        | mov [rcx], rax
        |9:
        | jmp rax
    ||}
|| }
|.endmacro

|.macro vmfrax, arg1
|| {
    ||vm_rblock_t *block = arg1;
    ||block->isfunc = true;
    ||void *got = vm_cache_get(&block->block->cache, block);
    ||if (got != NULL) {
        ||rnext->comps += block->comps;
        | mov32q64 RAX, ((uint64_t) (got))
    ||} else if (!block->block->mark) {
        ||got = vm_jit_rblock(state, block, true);
        ||rnext->comps += block->comps;
        | mov32q64 RAX, ((uint64_t) (got))
    ||} else {
        ||rnext->comps += 1;
        ||void **bit = vm_malloc(sizeof(void *));
        ||*bit = NULL;
        | mov32q64 RCX, ((uint64_t) (bit))
        | mov rax, [rcx]
        | test rax, rax
        |jnz >9
        | mov32q64 rArg0, ((uint64_t) state)
        | mov32q64 rArg1, ((uint64_t) block)
        | mov Rd(rArg2), 1
        | invoke vm_jit_rblock
        | mov32q64 RCX, ((uint64_t) (bit))
        | mov [rcx], rax
        |9:
    ||}
|| }
|.endmacro

enum {
    VM_TAB_R8,
    VM_TAB_R9,
    VM_TAB_R10,
    VM_TAB_R11,
    VM_TAB_NREGS,
};

static const uint8_t vm_reg_map[VM_TAB_NREGS] = {
    [VM_TAB_R8] = 8,
    [VM_TAB_R9] = 9,
    [VM_TAB_R10] = 10,
    [VM_TAB_R11] = 11,
};

|.macro vmload8, arg1, arg2
|| {
    || vm_arg_t arg = arg2;
    || if (arg.type == VM_ARG_REG) {
        ||if (arg.reg < VM_TAB_NREGS) {
            | mov Rb(arg1), Rb(vm_reg_map[arg.reg])
        ||} else {
            | mov Rb(arg1), [rsp + (8 * (arg.reg) + 8)]
        ||}
    || } else if (arg.type == VM_ARG_NUM) {
        || int8_t n = (int8_t) arg.num;
        | mov Rb(arg1), n
    ||}
|| }
|.endmacro

|.macro vmload16, arg1, arg2
|| {
    || vm_arg_t arg = arg2;
    || if (arg.type == VM_ARG_REG) {
        ||if (arg.reg < VM_TAB_NREGS) {
            | mov Rw(arg1), Rw(vm_reg_map[arg.reg])
        ||} else {
            | mov Rw(arg1), [rsp + (8 * (arg.reg) + 8)]
        ||}
    || } else if (arg.type == VM_ARG_NUM) {
        || int16_t n = (int16_t) arg.num;
        | mov Rw(arg1), n
    ||}
|| }
|.endmacro

|.macro vmload32, arg1, arg2
|| {
    || vm_arg_t arg = arg2;
    || if (arg.type == VM_ARG_REG) {
        ||if (arg.reg < VM_TAB_NREGS) {
            | mov Rd(arg1), Rd(vm_reg_map[arg.reg])
        ||} else {
            | mov Rd(arg1), [rsp + (8 * (arg.reg) + 8)]
        ||}
    || } else if (arg.type == VM_ARG_NUM) {
        || int32_t n = (int32_t) arg.num;
        | mov Rd(arg1), n
    ||}
|| }
|.endmacro

|.macro vmload64, arg1, arg2
|| {
    || vm_arg_t arg = arg2;
    || if (arg.type == VM_ARG_REG) {
        ||if (arg.reg < VM_TAB_NREGS) {
            | mov Rq(arg1), Rq(vm_reg_map[arg.reg])
        ||} else {
            | mov Rq(arg1), [rsp + (8 * (arg.reg) + 8)]
        ||}
    || } else if (arg.type == VM_ARG_NUM) {
        || int64_t n = (int64_t) arg.num;
        || int32_t t = (int32_t) n;
        || if (n == (int64_t) t) {
            | mov Rd(arg1), n
        || } else {
            | mov64 Rq(arg1), n
        || }
    ||}
|| }
|.endmacro

|.macro vmstore8, arg1, arg2
|| {
    ||vm_arg_t arg = (arg1);
    ||if (arg.reg < VM_TAB_NREGS) {
        | mov Rb(vm_reg_map[arg.reg]), Rb(arg2)
    ||} else {
        | mov [rsp + (8 * (arg).reg + 8)], Rb(arg2)
    ||}
|| }
|.endmacro

|.macro vmstore16, arg1, arg2
|| {
    ||vm_arg_t arg = (arg1);
    ||if (arg.reg < VM_TAB_NREGS) {
        | mov Rw(vm_reg_map[arg.reg]), Rw(arg2)
    ||} else {
        | mov [rsp + (8 * (arg).reg + 8)], Rw(arg2)
    ||}
|| }
|.endmacro

|.macro vmstore32, arg1, arg2
|| {
    ||vm_arg_t arg = (arg1);
    ||if (arg.reg < VM_TAB_NREGS) {
        | mov Rd(vm_reg_map[arg.reg]), Rd(arg2)
    ||} else {
        | mov [rsp + (8 * (arg).reg + 8)], Rd(arg2)
    ||}
|| }
|.endmacro

|.macro vmstore64, arg1, arg2
|| {
    ||vm_arg_t arg = (arg1);
    ||if (arg.reg < VM_TAB_NREGS) {
        | mov Rq(vm_reg_map[arg.reg]), Rq(arg2)
    ||} else {
        | mov [rsp + (8 * (arg).reg + 8)], Rq(arg2)
    ||}
|| }
|.endmacro

|.macro check, instr, size, av1, av2
|| {
    || vm_arg_t arg1 = av1;
    || vm_arg_t arg2 = av2;
    || if (arg2.type == VM_ARG_NUM) {
        | vmload..size RAX, arg1
        || switch (size) {
        || case 8: {
            | instr al, ((int8_t) arg2.num)
            || break;
        || }
        || case 16: {
            | instr ax, ((int16_t) arg2.num)
            || break;
        || }
        || case 32: {
            | instr eax, ((int32_t) arg2.num)
            || break;
        || }
        || case 64: {
            || int64_t n = (int64_t) arg2.num;
            || int32_t t = (int32_t) n;
            || if (n == (int64_t) t) {
                | instr rax, t
            || } else {
                | mov64 rcx, n
                | instr rax, rcx
            || }
            || break;
        || }
        || }
    || } else {
        | vmload..size RAX, arg1
        | vmload..size RCX, arg2
        || switch (size) {
        || case 8: {
            | instr al, cl
            || break;
        || }
        || case 16: {
            | instr ax, cx
            || break;
        || }
        || case 32: {
            | instr eax, ecx
            || break;
        || }
        || case 64: {
            | instr rax, rcx
            || break;
        || }
        || }
    || }
|| }
|.endmacro

void vm_jit_putchar(ptrdiff_t c) {
    printf("%c", (char) c);
}

static void* vm_jit_encode(vm_jit_state_t *state, dasm_State** d)
{
    size_t size;
    dasm_link(d, &size);
#ifdef _WIN32
    void* buf = VirtualAlloc(0, size, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE);
#else
    vm_jit_mmap_t *map = NULL;
    for (size_t i = 0; i < state->mapbuf.len; i++) {
        vm_jit_mmap_t *cur = &state->mapbuf.mmaps[state->mapbuf.len - i - 1];
        if (cur->used + size <= cur->alloc) {
            map = cur;
            break;
        }
    }
    // printf("%p / %zu", map, state->mapbuf.len);
    void *buf = NULL;
    if (map == NULL) {
        size_t blocks = 1;
        if (state->mapbuf.len < 12) {
            blocks = 1 << state->mapbuf.len;
        } else {
            blocks = 1 << 12;
        }
        size_t minsize = 4096 * blocks;
        size_t next_index = state->mapbuf.len + 1;
        if (next_index >= state->mapbuf.alloc) {
            state->mapbuf.alloc += next_index * 2;
            state->mapbuf.mmaps = vm_realloc(state->mapbuf.mmaps, sizeof(vm_jit_mmap_t) * state->mapbuf.alloc);
        }
        if (size < minsize) {
            map = &state->mapbuf.mmaps[next_index - 1];
            map->alloc = minsize;
            state->mapbuf.len = next_index;
            map->mem = mmap(0, map->alloc, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS | MAP_32BIT, -1, 0);
            map->used = size;
            buf = map->mem;
        } else {
            buf = mmap(0, map->alloc, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS | MAP_32BIT, -1, 0);
        }
    } else {
        buf = (void *) (((size_t) (map->mem)) + map->used);
        map->used += size;
    }
    
#endif
    dasm_encode(d, buf);
#ifdef _WIN32
    DWORD dwOld;
    VirtualProtect(buf, size, PAGE_EXECUTE_READ, &dwOld);
#endif
    // char chrs[256];
    // sprintf(chrs, "%p.bin", buf);
    // // static FILE *f = NULL;
    // FILE *f = NULL;
    // if (f == NULL) {
    //     f = fopen(chrs, "wb");
    // }
    // fwrite(buf, size, 1, f);
    // fclose(f);
    return buf;
}


static bool vm_jit_reg_used_after(vm_block_t *block, size_t ninstr, size_t reg) {
    while (ninstr < block->len) {
        vm_instr_t instr = block->instrs[ninstr];
        size_t argno = 0;
        while (true) {
            if (instr.args[argno].type == VM_ARG_NONE) {
                break;
            }
            if (instr.args[argno].type == VM_ARG_REG) {
                if (instr.args[argno].reg == reg) {
                    return true;
                }
            }
        }
        if (instr.out.type == VM_ARG_REG) {
            if (instr.out.reg == reg) {
                return false;
            }
        }
    }
    switch (block->branch.op) {
    case VM_BOP_EXIT: {
        return false;
    }
    case VM_BOP_RET: {
        return block->branch.args[0].type == VM_ARG_REG && block->branch.args[0].reg == reg;
    }
    case VM_BOP_JUMP: {
        if (block->branch.args[0].type == VM_ARG_REG && block->branch.args[0].reg == reg) {
            return true;
        }
    }
    case VM_BOP_BB: {
        if (block->branch.args[0].type == VM_ARG_REG && block->branch.args[0].reg == reg) {
            return true;
        }
        for (size_t i = 0; i < block->branch.targets[0]->nargs; i++) {
            if (block->branch.targets[0]->args[i].type == VM_ARG_REG && block->branch.targets[0]->args[i].reg == reg) {
                return true;
            }
        }
        return false;
    }
    case VM_BOP_BEQ: {
        if (block->branch.args[0].type == VM_ARG_REG && block->branch.args[0].reg == reg) {
            return true;
        }
        if (block->branch.args[1].type == VM_ARG_REG && block->branch.args[1].reg == reg) {
            return true;
        }
        for (size_t i = 0; i < block->branch.targets[0]->nargs; i++) {
            if (block->branch.targets[0]->args[i].type == VM_ARG_REG && block->branch.targets[0]->args[i].reg == reg) {
                return true;
            }
        }
        for (size_t i = 0; i < block->branch.targets[1]->nargs; i++) {
            if (block->branch.targets[1]->args[i].type == VM_ARG_REG && block->branch.targets[1]->args[i].reg == reg) {
                return true;
            }
        }
        return false;
    }
    case VM_BOP_BLT: {
        if (block->branch.args[0].type == VM_ARG_REG && block->branch.args[0].reg == reg) {
            return true;
        }
        if (block->branch.args[1].type == VM_ARG_REG && block->branch.args[1].reg == reg) {
            return true;
        }
        for (size_t i = 0; i < block->branch.targets[0]->nargs; i++) {
            if (block->branch.targets[0]->args[i].type == VM_ARG_REG && block->branch.targets[0]->args[i].reg == reg) {
                return true;
            }
        }
        for (size_t i = 0; i < block->branch.targets[1]->nargs; i++) {
            if (block->branch.targets[1]->args[i].type == VM_ARG_REG && block->branch.targets[1]->args[i].reg == reg) {
                return true;
            }
        }
        return false;
    }
    default: {
        __builtin_trap();
    }
    }
}

static void vm_jit_rblock_single(vm_jit_state_t *state, dasm_State **Dst, vm_rblock_t *rnext) {
    for (size_t ninstr = rnext->start; ninstr < rnext->block->len; ninstr++) {
        vm_instr_t instr = vm_rblock_type_specialize_instr(rnext->regs, rnext->block->instrs[ninstr]);
        if (!vm_rblock_type_check_instr(rnext->regs, instr)) __builtin_trap();
        switch (instr.op) {
        case VM_IOP_NOP: {
            break;
        }
        case VM_IOP_MOVE: {
            if (instr.args[0].type == VM_ARG_NUM) {
                int64_t n = instr.args[0].num;
                switch (instr.tag) {
                case VM_TAG_I8:{
                    | mov al, ((int8_t) (n));
                    | vmstore8 instr.out, RAX
                    break;
                }
                case VM_TAG_U8:{
                    | mov al, ((uint8_t) (n));
                    | vmstore8 instr.out, RAX
                    break;
                }
                case VM_TAG_I16:{
                    | mov ax, ((int16_t) (n));
                    | vmstore16 instr.out, RAX
                    break;
                }
                case VM_TAG_U16:{
                    | mov ax, ((uint16_t) (n));
                    | vmstore16 instr.out, RAX
                    break;
                }
                case VM_TAG_I32:{
                    | mov eax, ((int32_t) n);
                    | vmstore32 instr.out, RAX
                    break;
                }
                case VM_TAG_U32:{
                    | mov eax, ((uint32_t) n);
                    | vmstore32 instr.out, RAX
                    break;
                }
                case VM_TAG_I64: {
                    int32_t t = (int64_t) n;
                    if (n == (int64_t) t) {
                        | mov eax, n
                    } else {
                        | mov64 rax, n
                    }
                    | vmstore64 instr.out, RAX
                    break;
                }
                case VM_TAG_U64:{
                    uint32_t t = (uint64_t) n;
                    if (n == (uint64_t) t) {
                        | mov eax, n
                    } else {
                        | mov64 rax, n
                    }
                    | vmstore64 instr.out, RAX
                    break;
                }
                default: {
                    __builtin_trap();
                }
                }
            } else if (instr.args[0].type == VM_ARG_REG) {
                switch (instr.tag) {
                case VM_TAG_I8:
                case VM_TAG_U8:{
                    | vmload8 RAX, instr.args[0]
                    | vmstore8 instr.out, RAX
                    break;
                }
                case VM_TAG_I16:
                case VM_TAG_U16: {
                    | vmload16 RAX, instr.args[0]
                    | vmstore16 instr.out, RAX
                    break;
                }
                case VM_TAG_I32:
                case VM_TAG_U32: {
                    | vmload32 RAX, instr.args[0]
                    | vmstore32 instr.out, RAX
                    break;
                }
                case VM_TAG_I64:
                case VM_TAG_U64: {
                    | vmload64 RAX, instr.args[0]
                    | vmstore64 instr.out, RAX
                    break;
                }
                default: {
                    __builtin_trap();
                }
                }
            }
            // | vmload64 RAX, instr.args[0]
            // | vmstore64 instr.out, RAX
            break;
        }
        case VM_IOP_CAST: {
            break;
        }
        case VM_IOP_ADD: {
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8:{
                | vmload8 RAX, instr.args[0]
                | vmload8 RCX, instr.args[1]
                | add al, cl
                | vmstore8 instr.out, RAX
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16:{
                | vmload16 RAX, instr.args[0]
                | vmload16 RCX, instr.args[1]
                | add ax, cx
                | vmstore16 instr.out, RAX
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                | vmload32 RAX, instr.args[0]
                | vmload32 RCX, instr.args[1]
                | add eax, ecx
                | vmstore32 instr.out, RAX
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                | vmload64 RAX, instr.args[0]
                | vmload64 RCX, instr.args[1]
                | add rax, rcx
                | vmstore64 instr.out, RAX
                break;
            }
            default: {
                __builtin_trap();
            }
            }
            break;
        }
        case VM_IOP_SUB: {
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8:{
                | vmload8 RAX, instr.args[0]
                | vmload8 RCX, instr.args[1]
                | sub al, cl
                | vmstore8 instr.out, RAX
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16:{
                | vmload16 RAX, instr.args[0]
                | vmload16 RCX, instr.args[1]
                | sub ax, cx
                | vmstore16 instr.out, RAX
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                | vmload32 RAX, instr.args[0]
                | vmload32 RCX, instr.args[1]
                | sub eax, ecx
                | vmstore32 instr.out, RAX
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                | vmload64 RAX, instr.args[0]
                | vmload64 RCX, instr.args[1]
                | sub rax, rcx
                | vmstore64 instr.out, RAX
                break;
            }
            default: {
                __builtin_trap();
            }
            }
            break;
        }
        case VM_IOP_MUL: {
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8: {
                | vmload8 RAX, instr.args[0]
                | vmload8 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I8) {
                    | imul cl
                } else {
                    | mul cl
                }
                | vmstore8 instr.out, RAX
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16: {
                | vmload16 RAX, instr.args[0]
                | vmload16 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I16) {
                    | imul cx
                } else {
                    | mul cx
                }
                | vmstore16 instr.out, RAX
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                | vmload32 RAX, instr.args[0]
                | vmload32 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I32) {
                    | imul ecx
                } else {
                    | mul ecx
                }
                | vmstore32 instr.out, RAX
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                | vmload64 RAX, instr.args[0]
                | vmload64 RCX, instr.args[1]
                if (instr.tag == VM_TAG_I64) {
                    | imul rcx
                } else {
                    | mul rcx
                }
                | vmstore64 instr.out, RAX
                break;
            }
            default: {
                __builtin_trap();
            }
            }
            break;
        }
        case VM_IOP_DIV: {
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8: {
                if (instr.tag == VM_TAG_I8) {
                    | vmload8 RAX, instr.args[0]
                    | vmload8 RCX, instr.args[1]
                    | cbw
                    | idiv cl
                } else {
                    | xor ax, ax
                    | vmload8 RAX, instr.args[0]
                    | vmload8 RCX, instr.args[1]
                    | div cl
                }
                | vmstore8 instr.out, RAX
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16: {
                if (instr.tag == VM_TAG_I16) {
                    | vmload16 RAX, instr.args[0]
                    | vmload16 RCX, instr.args[1]
                    | cwd
                    | idiv cx
                } else {
                    | xor dx, dx
                    | vmload16 RAX, instr.args[0]
                    | vmload16 RCX, instr.args[1]
                    | div cx
                }
                | vmstore16 instr.out, RAX
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                if (instr.tag == VM_TAG_I32) {
                    | vmload32 RAX, instr.args[0]
                    | vmload32 RCX, instr.args[1]
                    | cdq
                    | idiv ecx
                } else {
                    | xor edx, edx
                    | vmload32 RAX, instr.args[0]
                    | vmload32 RCX, instr.args[1]
                    | div ecx
                }
                | vmstore32 instr.out, RAX
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                if (instr.tag == VM_TAG_I64) {
                    | vmload64 RAX, instr.args[0]
                    | vmload64 RCX, instr.args[1]
                    | cqo
                    | idiv rcx
                } else {
                    | xor edx, edx
                    | vmload64 RAX, instr.args[0]
                    | vmload64 RCX, instr.args[1]
                    | div rcx
                }
                | vmstore64 instr.out, RAX
                break;
            }
            default: {
                __builtin_trap();
            }
            }
            break;
        }
        case VM_IOP_MOD: {
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8: {
                if (instr.tag == VM_TAG_I8) {
                    | vmload8 RAX, instr.args[0]
                    | vmload8 RCX, instr.args[1]
                    | cbw
                    | idiv cl
                } else {
                    | xor ax, ax
                    | vmload8 RAX, instr.args[0]
                    | vmload8 RCX, instr.args[1]
                    | div cl
                }
                | shr ax, 8
                | vmstore8 instr.out, RAX
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16: {
                if (instr.tag == VM_TAG_I16) {
                    | vmload16 RAX, instr.args[0]
                    | vmload16 RCX, instr.args[1]
                    | cwd
                    | idiv cx
                } else {
                    | xor dx, dx
                    | vmload16 RAX, instr.args[0]
                    | vmload16 RCX, instr.args[1]
                    | div cx
                }
                | vmstore16 instr.out, RDX
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                if (instr.tag == VM_TAG_I32) {
                    | vmload32 RAX, instr.args[0]
                    | vmload32 RCX, instr.args[1]
                    | cdq
                    | idiv ecx
                } else {
                    | xor edx, edx
                    | vmload32 RAX, instr.args[0]
                    | vmload32 RCX, instr.args[1]
                    | div ecx
                }
                | vmstore32 instr.out, RDX
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                if (instr.tag == VM_TAG_I64) {
                    | vmload64 RAX, instr.args[0]
                    | vmload64 RCX, instr.args[1]
                    | cqo
                    | idiv rcx
                } else {
                    | xor edx, edx
                    | vmload64 RAX, instr.args[0]
                    | vmload64 RCX, instr.args[1]
                    | div rcx
                }
                | vmstore64 instr.out, RDX
                break;
            }
            default: {
                __builtin_trap();
            }
            }
            break;
        }
        case VM_IOP_CALL: {
            if (instr.args[0].type == VM_ARG_FUNC) {
                vm_tags_t *argtypes = vm_rblock_regs_empty(VM_NREGS);
                for (size_t i = 1; instr.args[i].type != VM_ARG_NONE; i++) {
                    argtypes->tags[i] = rnext->regs->tags[instr.args[i].reg];
                }
                vm_rblock_t *func = vm_rblock_new(instr.args[0].func, argtypes);
                | mov [rsp+8], r8
                | mov [rsp+16], r9
                | mov [rsp+24], r10
                | mov [rsp+32], r11
                | regsave
                |vmfrax func
                for (int32_t i = 1; instr.args[i].type != VM_ARG_NONE; i++) {
                    size_t reg = instr.args[i].reg;
                    switch (reg) {
                    case 0: {
                        | mov Rq(vm_reg_map[i]), [rsp+8]
                        break;
                    }
                    case 1: {
                        | mov Rq(vm_reg_map[i]), [rsp+16]
                        break;
                    }
                    case 2: {
                        | mov Rq(vm_reg_map[i]), [rsp+24]
                        break;
                    }
                    case 3: {
                        | mov Rq(vm_reg_map[i]), [rsp+32]
                        break;
                    }
                    default: {
                        switch (rnext->regs->tags[instr.args[i].reg]) {
                            case VM_TAG_I8:
                            case VM_TAG_U8: {
                                | vmload8 vm_reg_map[i], instr.args[i] 
                                break;
                            }
                            case VM_TAG_I16:
                            case VM_TAG_U16: {
                                | vmload16 vm_reg_map[i], instr.args[i] 
                                break;
                            }
                            case VM_TAG_I32:
                            case VM_TAG_U32: {
                                | vmload32 vm_reg_map[i], instr.args[i] 
                                break;
                            }
                            case VM_TAG_I64:
                            case VM_TAG_U64: {
                                | vmload64 vm_reg_map[i], instr.args[i] 
                                break;
                            }
                            default: {
                                __builtin_trap();
                            }
                        }
                    }
                    }
                }
                | call rax
                | mov r8, [rsp+8]
                | mov r9, [rsp+16]
                | mov r10, [rsp+24]
                | mov r11, [rsp+32]
                | vmstore64 instr.out, RAX
            }
            break;
        }
        case VM_IOP_OUT: {
            | xor Rd(rArg0), Rd(rArg0)
            switch (instr.tag) {
            case VM_TAG_I8:
            case VM_TAG_U8: {
                | vmload8 rArg0, instr.args[0]
                break;
            }
            case VM_TAG_I16:
            case VM_TAG_U16: {
                | vmload16 rArg0, instr.args[0]
                break;
            }
            case VM_TAG_I32:
            case VM_TAG_U32: {
                | vmload32 rArg0, instr.args[0]
                break;
            }
            case VM_TAG_I64:
            case VM_TAG_U64: {
                | vmload64 rArg0, instr.args[0]
                break;
            }
            default: {
                __builtin_trap();
            }
            }
            | invoke vm_jit_putchar
            break;
        }
        case VM_IOP_IN: {
            printf("IN\n");
            break;
        }
        case VM_IOP_BNOT: {
            break;
        }
        case VM_IOP_BOR: {
            break;
        }
        case VM_IOP_BAND: {
            break;
        }
        case VM_IOP_BXOR: {
            break;
        }
        case VM_IOP_BSHL: {
            break;
        }
        case VM_IOP_BSHR: {
            break;
        }
        }
        if (instr.out.type == VM_ARG_REG) {
            rnext->regs->tags[instr.out.reg] = instr.tag;
        }
    }
    vm_branch_t branch = vm_rblock_type_specialize_branch(rnext->regs, rnext->block->branch);
    if (!vm_rblock_type_check_branch(rnext->regs, branch)) __builtin_trap();
     switch (branch.op) {
    case VM_BOP_EXIT: {
        break;
    }
    case VM_BOP_RET: {
        break;
    }
    case VM_BOP_JUMP: {
        if (rnext->targets[0] == NULL) {
            rnext->targets[0] = vm_rblock_new(branch.targets[0], rnext->regs);
        }
        break;
    }
    case VM_BOP_BB: {
        if (rnext->targets[0] == NULL) {
            rnext->targets[0] = vm_rblock_new(branch.targets[0], rnext->regs);
        }
        if (rnext->targets[1] == NULL) {
            rnext->targets[1] = vm_rblock_new(branch.targets[1], rnext->regs);
        }
        break;
    }
    case VM_BOP_BEQ: {
        if (rnext->targets[0] == NULL) {
            rnext->targets[0] = vm_rblock_new(branch.targets[0], rnext->regs);
        }
        if (rnext->targets[1] == NULL) {
            rnext->targets[1] = vm_rblock_new(branch.targets[1], rnext->regs);
        }
        break;
    }
    case VM_BOP_BLT: {
        if (rnext->targets[0] == NULL) {
            rnext->targets[0] = vm_rblock_new(branch.targets[0], rnext->regs);
        }
        if (rnext->targets[1] == NULL) {
            rnext->targets[1] = vm_rblock_new(branch.targets[1], rnext->regs);
        }
        break;
    }
    }
    switch (branch.op) {
    case VM_BOP_EXIT: {
        | mov64 rax, ((uint64_t) &state->exitptr)
        | mov rsp, [rax]
        | ret
        break;
    }
    case VM_BOP_RET: {
        switch (branch.tag) {
        case VM_TAG_I8:
        case VM_TAG_U8: {
            | vmload8 RAX, branch.args[0]
            break;
        }
        case VM_TAG_I16:
        case VM_TAG_U16: {
            | vmload16 RAX, branch.args[0]
            break;
        }
        case VM_TAG_I32:
        case VM_TAG_U32: {
            | vmload32 RAX, branch.args[0]
            break;
        }
        case VM_TAG_I64:
        case VM_TAG_U64: {
            | vmload64 RAX, branch.args[0]
            break;
        }
        }
        | add rsp, state->push 
        | ret
        break;
    }
    case VM_BOP_JUMP: {
        | vmjump rnext->targets[0]
        break;
    }
    case VM_BOP_BB: {
        switch (branch.tag) {
        case VM_TAG_I8:
        case VM_TAG_U8: {
            | vmload8 RAX, branch.args[0]
            | test al, al
            break;
        }
        case VM_TAG_I16:
        case VM_TAG_U16: {
            | vmload16 RAX, branch.args[0]
            | test ax, ax
            break;
        }
        case VM_TAG_I32:
        case VM_TAG_U32: {
            | vmload32 RAX, branch.args[0]
            | test eax, eax
            break;
        }
        case VM_TAG_I64:
        case VM_TAG_U64: {
            | vmload64 RAX, branch.args[0]
            | test rax, rax
            break;
        }
        }
        | jnz >1
        | vmjump rnext->targets[1]
        |1:
        | vmjump rnext->targets[0]
        break;
    }
    case VM_BOP_BEQ: {
        switch (branch.tag) {
        case VM_TAG_I8:
        case VM_TAG_U8: {
            | check cmp, 8, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I16:
        case VM_TAG_U16: {
            | check cmp, 16, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I32:
        case VM_TAG_U32: {
            | check cmp, 32, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I64:
        case VM_TAG_U64: {
            | check cmp, 64, (branch.args[0]), (branch.args[1])
            break;
        }
        }
        | je >1
        | vmjump rnext->targets[1]
        |1:
        | vmjump rnext->targets[0]
        break;
    }
    case VM_BOP_BLT: {
        switch (branch.tag) {
        case VM_TAG_I8:
        case VM_TAG_U8: {
            | check cmp, 8, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I16:
        case VM_TAG_U16: {
            | check cmp, 16, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I32:
        case VM_TAG_U32: {
            | check cmp, 32, (branch.args[0]), (branch.args[1])
            break;
        }
        case VM_TAG_I64:
        case VM_TAG_U64: {
            | check cmp, 64, (branch.args[0]), (branch.args[1])
            break;
        }
        }
        switch (branch.tag) {
        case VM_TAG_I8:
        case VM_TAG_I16:
        case VM_TAG_I32:
        case VM_TAG_I64: {
            | jl >1
            break;
        }
        case VM_TAG_U8:
        case VM_TAG_U16:
        case VM_TAG_U32:
        case VM_TAG_U64: {
            | jb >1
            break;
        }
        }
        | vmjump rnext->targets[1]
        |1:
        | vmjump rnext->targets[0]
        break;
    }
    }
    // state->depth -= 1;
}

#define Dst (&d)

static void *vm_jit_rblock(vm_jit_state_t *state, vm_rblock_t *rblock, bool isfunc) {
    size_t old_push = state->push;
    size_t count = state->count++;
    void *cached = vm_cache_get(&rblock->block->cache, rblock);
    if (cached != NULL) {
        return cached;
    }
    bool last_mark = rblock->block->mark;
    rblock->block->mark = true;
    dasm_State* d;
    |.section code
    dasm_init(&d, DASM_MAXSECTION);
    |.globals lbl_
    void* labels[lbl__MAX];
    dasm_setupglobal(&d, labels, lbl__MAX);
    |.actionlist act
    dasm_setup(&d, act);
    dasm_growpc(&d, 16);
    |.code
    |->main:
    size_t nregs = rblock->block->nregs;
    if (nregs < rblock->block->nargs + 1) {
        nregs = rblock->block->nargs + 1;
    }
    if (nregs < 8) {
        nregs = 8;
    }
    state->push = nregs * 8 + 8;
    while (state->push % 16 != 8) {
        state->push += 1;
    }
    if (count == 0) {
        | mov64 rax, ((uint64_t) &state->exitptr)
        | mov [rax], rsp
        | sub rsp, state->push
    } else if (isfunc) {
        | sub rsp, state->push
    }
    vm_tags_t *tags_save = rblock->regs;
    rblock->regs = vm_rblock_regs_dup(rblock->regs, VM_NREGS);
    // vm_rblock_t *rnext = vm_rblock_new(rblock->block, types);
    // rnext->start = rblock->start;
    // rnext->isfunc = isfunc;
    vm_jit_rblock_single(state, &d, rblock);
    vm_jit_encode(state, &d);
    dasm_free(&d);
    void *fn = labels[lbl_main];
    // if (rnext->comps == 0) {
    vm_cache_set(&rblock->block->cache, rblock, fn);
    // }
    rblock->regs = tags_save;
    rblock->block->mark = last_mark;
    state->push = old_push;
    return fn;
}

vm_jit_state_t *vm_jit_state_new(void) {
    vm_jit_state_t *ret = vm_malloc(sizeof(vm_jit_state_t));
    *ret = (vm_jit_state_t) {0};
    return ret;
}

void vm_jit_state_free(vm_jit_state_t *state) {
    vm_free(state);
}

void vm_jit_run(void *state_ptr, vm_block_t *block) {
    vm_jit_state_t *state = state_ptr;
    vm_rblock_t *rblock = vm_rblock_new(block, vm_rblock_regs_empty(block->nregs));
    size_t(*fn)(void) = vm_jit_rblock(state, rblock, true);
    fn();
    state->count = 0;
}
